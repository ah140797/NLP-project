{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS_FOLDER = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpc_losses = {}\n",
    "eval_losses = {}\n",
    "\n",
    "# Traverse through all folders and read trainer_state.json files\n",
    "for subdir, _, files in os.walk(ALL_MODELS_FOLDER):\n",
    "    if \"trainer_state.json\" in files:\n",
    "        file_path = os.path.join(subdir, \"trainer_state.json\")\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            # Collect all eval_bpc values in a list\n",
    "            bpc_list = []\n",
    "            eval_loss_list = []\n",
    "            for log_entry in data.get(\"log_history\", []):\n",
    "                if \"eval_bpc\" in log_entry:\n",
    "                    bpc_list.append(log_entry[\"eval_bpc\"])\n",
    "                elif if \"eval_loss\" in log_entry:\n",
    "                    eval_loss_list.append(log_entry[\"eval_loss\"])\n",
    "\n",
    "            # Extract only the model name from the subdirectory path\n",
    "            match = re.search(r\"models[\\\\/](.*?)(\\\\|/|$)\", subdir)\n",
    "            if match:\n",
    "                model_name = match.group(1)\n",
    "                if bpc_list:\n",
    "                    bpc_losses[model_name] = bpc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_es_BPE_vs10000': [3.9953058180117345,\n",
       "  3.815965256450828,\n",
       "  3.6624676062772807,\n",
       "  3.481875157404405,\n",
       "  3.315451010890085,\n",
       "  3.0786520799016173,\n",
       "  3.0615162639338633,\n",
       "  2.991322781436518,\n",
       "  2.9219343985406874,\n",
       "  2.9342840626559132,\n",
       "  2.920990074048429,\n",
       "  2.8923648238112234,\n",
       "  2.9088227385815504,\n",
       "  2.8587452818780017,\n",
       "  2.831865208228805,\n",
       "  2.8834524070248495,\n",
       "  2.7975733162665746,\n",
       "  2.8040014855765003,\n",
       "  2.8111562262478,\n",
       "  2.7733700315133722,\n",
       "  2.757835074782902,\n",
       "  2.768960140978562,\n",
       "  2.73191926615214,\n",
       "  2.769781908432716,\n",
       "  2.728348755105268,\n",
       "  2.7338062432001213,\n",
       "  2.734358180148394,\n",
       "  2.7231005502507446,\n",
       "  2.7593194678475075,\n",
       "  2.695736842111602,\n",
       "  2.7494148338223803,\n",
       "  2.709901806599649,\n",
       "  2.7272720019433665,\n",
       "  2.7156565129203374,\n",
       "  2.7293385863560506,\n",
       "  2.763826265201652,\n",
       "  2.68039728174644,\n",
       "  2.7158696393102053,\n",
       "  2.753272422638411,\n",
       "  2.68973129989913,\n",
       "  2.695348935977371,\n",
       "  2.733073509204307,\n",
       "  2.74277574325526,\n",
       "  2.6612346010851176,\n",
       "  2.6915696649563388,\n",
       "  2.708089475270436,\n",
       "  2.684374403187392,\n",
       "  2.6956457511260514,\n",
       "  2.7054502866368746,\n",
       "  2.6853188234987706,\n",
       "  2.668947997418598,\n",
       "  2.669865451807563,\n",
       "  2.68768723045308,\n",
       "  2.660614246735573,\n",
       "  2.6940486754100963,\n",
       "  2.7017844503930375,\n",
       "  2.7010880773283223,\n",
       "  2.6648680901557147,\n",
       "  2.671946879757796,\n",
       "  2.694923073710073,\n",
       "  2.646833557166852,\n",
       "  2.684975610541015,\n",
       "  2.6419787690898087,\n",
       "  2.6466254164024865,\n",
       "  2.6709054993262273,\n",
       "  2.6422065279418345,\n",
       "  2.6665257861590916,\n",
       "  2.693907705340461,\n",
       "  2.68202221221842,\n",
       "  2.7070705678287643,\n",
       "  2.6786665065215045,\n",
       "  2.684357926430445,\n",
       "  2.6799101327152597,\n",
       "  2.604714159414037,\n",
       "  2.6730666053916234,\n",
       "  2.65792530243399,\n",
       "  2.715006166224665,\n",
       "  2.6579316122379475,\n",
       "  2.7273014966898703,\n",
       "  2.723815217290613,\n",
       "  2.6982477081769187,\n",
       "  2.628669307446646,\n",
       "  2.6941014484211396,\n",
       "  2.7109256055296815,\n",
       "  2.6674567572026793,\n",
       "  2.6710594508904775,\n",
       "  2.6232705865342254,\n",
       "  2.6522937303807717,\n",
       "  2.6686761397131953,\n",
       "  2.660148810031649,\n",
       "  2.656362842400131,\n",
       "  2.6704504183057503,\n",
       "  2.7465415563929967,\n",
       "  2.7066560462707674,\n",
       "  2.670324530823113,\n",
       "  2.6260866840525323,\n",
       "  2.6698054441632073,\n",
       "  2.5907923714621823,\n",
       "  2.594717482697975,\n",
       "  2.692558796710009,\n",
       "  2.673209491776784,\n",
       "  2.6494045629942407,\n",
       "  2.6474990187965712,\n",
       "  2.6444605260169807,\n",
       "  2.666513700560883,\n",
       "  2.6512289762482237,\n",
       "  2.628475997448936,\n",
       "  2.6745663682444487,\n",
       "  2.668779072861391,\n",
       "  2.6615114319044317,\n",
       "  2.6641893767526437,\n",
       "  2.6726002398279043,\n",
       "  2.6606756617377605,\n",
       "  2.6434488640792417,\n",
       "  2.652499136217948,\n",
       "  2.6721260877401387],\n",
       " 'model_es_BPE_vs20000': [3.6850032764120515,\n",
       "  3.5762800331006406,\n",
       "  3.4552675320535675,\n",
       "  3.228134795326567,\n",
       "  3.109338325443192,\n",
       "  2.887943322096282,\n",
       "  2.7463775361540455,\n",
       "  2.6896915105357238,\n",
       "  2.6757742197025713,\n",
       "  2.6545379033377268,\n",
       "  2.6677288610291554,\n",
       "  2.6766335964562074,\n",
       "  2.6501113874876463,\n",
       "  2.6443268673854092,\n",
       "  2.625336464528076,\n",
       "  2.5810085889202576,\n",
       "  2.5278331534486025,\n",
       "  2.6505984741296174,\n",
       "  2.5655330837691523,\n",
       "  2.5187016851232844,\n",
       "  2.5279528854161675,\n",
       "  2.531497825708902,\n",
       "  2.527724972992932,\n",
       "  2.5839354993128776,\n",
       "  2.527260244612526,\n",
       "  2.5515809325494407,\n",
       "  2.5154178184090195,\n",
       "  2.500476062355554,\n",
       "  2.5293921999399074,\n",
       "  2.5200854588618906,\n",
       "  2.5111652142439613,\n",
       "  2.525503474060542,\n",
       "  2.5227794507986667,\n",
       "  2.509706195555088,\n",
       "  2.486152645980343,\n",
       "  2.511747558015894,\n",
       "  2.451194592100113,\n",
       "  2.455882421143172,\n",
       "  2.5053943277940727,\n",
       "  2.4611365957337936,\n",
       "  2.4543374977362924,\n",
       "  2.4933598588317567,\n",
       "  2.4914523572855987,\n",
       "  2.4757830299237513,\n",
       "  2.457507618386285,\n",
       "  2.468297312422383,\n",
       "  2.48481348675638,\n",
       "  2.456629915986323,\n",
       "  2.4434570242941307,\n",
       "  2.4467940737087805,\n",
       "  2.4651694547300216,\n",
       "  2.387401241865093,\n",
       "  2.462169661444208,\n",
       "  2.4898012350506273,\n",
       "  2.44051719208292,\n",
       "  2.4885544771933965,\n",
       "  2.4935829654650155,\n",
       "  2.4389036845354575,\n",
       "  2.46080818394024,\n",
       "  2.444371377602381,\n",
       "  2.3988437070634885,\n",
       "  2.4792882000861467,\n",
       "  2.4097811122813617,\n",
       "  2.4027172478620287,\n",
       "  2.4522347903539012,\n",
       "  2.3887805096892674,\n",
       "  2.4279606461863468,\n",
       "  2.4409668442729386,\n",
       "  2.3989797194451885,\n",
       "  2.4406218832224034,\n",
       "  2.4473404953748084,\n",
       "  2.4660870943662627,\n",
       "  2.445264078581239,\n",
       "  2.3925218912800488,\n",
       "  2.418368304934695,\n",
       "  2.450305996727187,\n",
       "  2.4363806273362574,\n",
       "  2.455910767241926,\n",
       "  2.434181773402552,\n",
       "  2.4033611044464287,\n",
       "  2.4143789363529797,\n",
       "  2.3778175565924142,\n",
       "  2.4275666727565177,\n",
       "  2.477867097809543,\n",
       "  2.451282100316696,\n",
       "  2.37358246150278,\n",
       "  2.4368117112031933,\n",
       "  2.4275490730188234,\n",
       "  2.3859073908782826,\n",
       "  2.390946089393473,\n",
       "  2.378931359943149,\n",
       "  2.4162527664809645,\n",
       "  2.4310802458869785,\n",
       "  2.374053457670075,\n",
       "  2.4253269215127187,\n",
       "  2.427550053968122,\n",
       "  2.413982445126629,\n",
       "  2.353867671404457,\n",
       "  2.349221370884383,\n",
       "  2.3878958808831383,\n",
       "  2.418797977893478,\n",
       "  2.415327581780752,\n",
       "  2.379689978607406,\n",
       "  2.4175022829382304,\n",
       "  2.378153741710173,\n",
       "  2.4420302965408776,\n",
       "  2.450495666822319,\n",
       "  2.4010795058046983,\n",
       "  2.4105839216942524,\n",
       "  2.420198424052278,\n",
       "  2.4056469781087673,\n",
       "  2.418531570466643,\n",
       "  2.3733845989225664,\n",
       "  2.4094810516245304,\n",
       "  2.4326458909478186,\n",
       "  2.3998244161086255],\n",
       " 'model_es_BPE_vs30000': [3.707493660859889,\n",
       "  3.512577868336586,\n",
       "  3.4356817020992554,\n",
       "  3.216273229727534,\n",
       "  3.0656550093835353,\n",
       "  2.8223298498852585,\n",
       "  2.7277781732854574,\n",
       "  2.6398266791471263,\n",
       "  2.5840477093972285,\n",
       "  2.6267732984558623,\n",
       "  2.598070457021605,\n",
       "  2.6687076463533694,\n",
       "  2.576932772251951,\n",
       "  2.569534311706636,\n",
       "  2.5559143220245515,\n",
       "  2.525470194610971,\n",
       "  2.45933211466282,\n",
       "  2.5399753995412913,\n",
       "  2.5257160585821508,\n",
       "  2.5286232729901528,\n",
       "  2.4781955048690407,\n",
       "  2.5084781489314207,\n",
       "  2.4473780079325542,\n",
       "  2.5362937483163535,\n",
       "  2.445540996143228,\n",
       "  2.443399908406277,\n",
       "  2.4642522719350186,\n",
       "  2.453583191751496,\n",
       "  2.484769401380388,\n",
       "  2.4811334914597207,\n",
       "  2.451671282777037,\n",
       "  2.440902664952354,\n",
       "  2.4422991246216714,\n",
       "  2.4324848244265835,\n",
       "  2.4405903543525,\n",
       "  2.43371354793533,\n",
       "  2.4638282997792054,\n",
       "  2.4506355164943012,\n",
       "  2.4579193714581424,\n",
       "  2.4379343569683307,\n",
       "  2.440671329213607,\n",
       "  2.4398683652475093,\n",
       "  2.423664660250564,\n",
       "  2.402886040496479,\n",
       "  2.4098245302945007,\n",
       "  2.4204744627804162,\n",
       "  2.4140097270126093,\n",
       "  2.3767934028731457,\n",
       "  2.3452757300214357,\n",
       "  2.409007728368656,\n",
       "  2.41898281965981,\n",
       "  2.4001899768006325,\n",
       "  2.453822137155188,\n",
       "  2.3921985171394615,\n",
       "  2.3509474396549788,\n",
       "  2.3941352080026523,\n",
       "  2.4543024605737,\n",
       "  2.3866303584634516,\n",
       "  2.37599465894526,\n",
       "  2.3871665656284287,\n",
       "  2.3425563986295868,\n",
       "  2.4685271180570005,\n",
       "  2.385870840341578,\n",
       "  2.3917386874251942,\n",
       "  2.411444904460068,\n",
       "  2.369656736771934,\n",
       "  2.4265864960178933,\n",
       "  2.3742836452481235,\n",
       "  2.3651023890035106,\n",
       "  2.402541429183397,\n",
       "  2.400025771869388,\n",
       "  2.3539843515959284,\n",
       "  2.366811464961065,\n",
       "  2.406420880556362,\n",
       "  2.375801043892775,\n",
       "  2.3439241332663854,\n",
       "  2.3764727433033928,\n",
       "  2.3614673416298717,\n",
       "  2.3407925877551277,\n",
       "  2.3635427860015406,\n",
       "  2.3798963257306918,\n",
       "  2.3164555368097433,\n",
       "  2.3941773813876774,\n",
       "  2.395870706345585,\n",
       "  2.3636563708838914,\n",
       "  2.3313658532337636,\n",
       "  2.361911473713335,\n",
       "  2.339266358826042,\n",
       "  2.365381201136733,\n",
       "  2.338709696486346,\n",
       "  2.3620393650232376,\n",
       "  2.3376948496264407,\n",
       "  2.3292821871626224,\n",
       "  2.322906173436725,\n",
       "  2.3294946917744483,\n",
       "  2.3552453279863284,\n",
       "  2.353298489015643,\n",
       "  2.3180440980302377,\n",
       "  2.3119313972656803,\n",
       "  2.370971052347906,\n",
       "  2.3301153843582565,\n",
       "  2.360211856467778,\n",
       "  2.3378187784248134,\n",
       "  2.322674973695677,\n",
       "  2.3640653375955325,\n",
       "  2.3609580273935857,\n",
       "  2.3657707825861776,\n",
       "  2.3530862293723662,\n",
       "  2.388960369864494,\n",
       "  2.367985252984174,\n",
       "  2.3729208594122757,\n",
       "  2.3337539664717832,\n",
       "  2.3385887635278375,\n",
       "  2.3382653282783723,\n",
       "  2.3643269252355728,\n",
       "  2.3403760981738975],\n",
       " 'model_es_BPE_vs40000': [3.6356172572964884,\n",
       "  3.4662265907806447,\n",
       "  3.489260444213256,\n",
       "  3.259855384813615,\n",
       "  3.1050252796631375,\n",
       "  2.8510642288213277,\n",
       "  2.71876573784444,\n",
       "  2.6477171173925016,\n",
       "  2.523311058127255,\n",
       "  2.5562613620357015,\n",
       "  2.544071747605784,\n",
       "  2.577698456600759,\n",
       "  2.532810259502938,\n",
       "  2.508130901143826,\n",
       "  2.484304894546066,\n",
       "  2.4848995492902377,\n",
       "  2.496001121624126,\n",
       "  2.481170461131832,\n",
       "  2.474673408163761,\n",
       "  2.445407402962273,\n",
       "  2.4428385410076334,\n",
       "  2.43471560128022,\n",
       "  2.417001523076507,\n",
       "  2.4653936584093694,\n",
       "  2.464139713054158,\n",
       "  2.4179068653665934,\n",
       "  2.4535083487533287,\n",
       "  2.4261751086148315,\n",
       "  2.4227546344493858,\n",
       "  2.406726191943115,\n",
       "  2.3634212394384226,\n",
       "  2.4340061704044498,\n",
       "  2.403847713734149,\n",
       "  2.376394576128938,\n",
       "  2.402125061599379,\n",
       "  2.422499407558863,\n",
       "  2.38306697010616,\n",
       "  2.3684006729780043,\n",
       "  2.3951376462323357,\n",
       "  2.377376634480918,\n",
       "  2.429022357203049,\n",
       "  2.403132142371192,\n",
       "  2.3832893347997812,\n",
       "  2.3408632632602613,\n",
       "  2.377310189465975,\n",
       "  2.394194519941958,\n",
       "  2.3595402661948515,\n",
       "  2.3429813942833086,\n",
       "  2.3460281535711305,\n",
       "  2.377479726312536,\n",
       "  2.349688042527831,\n",
       "  2.3865082012514964,\n",
       "  2.375116835563389,\n",
       "  2.348729860323998,\n",
       "  2.370120196501492,\n",
       "  2.3641621736654264,\n",
       "  2.390499935573075,\n",
       "  2.3352818286410675,\n",
       "  2.342752347582077,\n",
       "  2.3587487047750058,\n",
       "  2.3165516604447354,\n",
       "  2.4133180617017773,\n",
       "  2.4015887479675455,\n",
       "  2.3184132501416004,\n",
       "  2.3395842914214118,\n",
       "  2.336609187876261,\n",
       "  2.3209910714748268,\n",
       "  2.3534937045912523,\n",
       "  2.312959704458336,\n",
       "  2.3700231177332562,\n",
       "  2.342844485200045,\n",
       "  2.3334606228459647,\n",
       "  2.3493072130395958,\n",
       "  2.3469136928301944,\n",
       "  2.355971502620843,\n",
       "  2.3097964077355537,\n",
       "  2.3504704682252857,\n",
       "  2.3426170503613144,\n",
       "  2.3191089657176356,\n",
       "  2.3507574891174086,\n",
       "  2.3524641907201795,\n",
       "  2.2700217095706208,\n",
       "  2.306903545254285,\n",
       "  2.331889284383523,\n",
       "  2.2722158292664565,\n",
       "  2.2874493994982297,\n",
       "  2.3128494360533662,\n",
       "  2.3153807473567136,\n",
       "  2.2854013538715376,\n",
       "  2.3132357252991964,\n",
       "  2.317726824957229,\n",
       "  2.2701613582068085,\n",
       "  2.322019761369691,\n",
       "  2.3376518440383984,\n",
       "  2.3225645473989864,\n",
       "  2.3186140811964844,\n",
       "  2.303667588980983,\n",
       "  2.3198519914413755,\n",
       "  2.315299885172954,\n",
       "  2.327913256739508,\n",
       "  2.327367011059075,\n",
       "  2.3389844926026813,\n",
       "  2.262900009936494,\n",
       "  2.294513701317144,\n",
       "  2.3311020097003317,\n",
       "  2.317887419488402,\n",
       "  2.325345479587675,\n",
       "  2.3342976837066614,\n",
       "  2.320302184445588,\n",
       "  2.3144461186093364,\n",
       "  2.296745682267203,\n",
       "  2.247160583747297,\n",
       "  2.279606986881175,\n",
       "  2.319147346027302,\n",
       "  2.3203040106936226,\n",
       "  2.3239364349593212],\n",
       " 'model_tr_BPE_vs10000': [3.7023106617982497,\n",
       "  3.564930728699328,\n",
       "  3.50310257565023,\n",
       "  3.3350488963426255,\n",
       "  3.1898262440024356,\n",
       "  3.0293579591183866,\n",
       "  3.0262583941836714,\n",
       "  3.0142010824154273,\n",
       "  2.9502541759373258,\n",
       "  3.042245389064317,\n",
       "  2.999277064584359,\n",
       "  2.984743385513794,\n",
       "  2.9481778559863177,\n",
       "  2.906874632098861,\n",
       "  2.904354182328317,\n",
       "  2.877734203488012,\n",
       "  2.910301182703685,\n",
       "  2.8717513963089365,\n",
       "  2.859884842732124,\n",
       "  2.8666306003194197,\n",
       "  2.855378535318008,\n",
       "  2.8342724865577122,\n",
       "  2.8021706630450836,\n",
       "  2.802684863103727,\n",
       "  2.8040698288941552,\n",
       "  2.7688623867215405,\n",
       "  2.8555423144331398,\n",
       "  2.8261057870570654,\n",
       "  2.79993470168983,\n",
       "  2.794688310118748,\n",
       "  2.8064344009814235,\n",
       "  2.7318674328112587,\n",
       "  2.7702151628999467,\n",
       "  2.777346919273362,\n",
       "  2.7480831629291194,\n",
       "  2.7868864240060804,\n",
       "  2.725384163826155,\n",
       "  2.7474097936613546,\n",
       "  2.794566225215422,\n",
       "  2.7546312774132415,\n",
       "  2.735226820859472,\n",
       "  2.7600771742299113,\n",
       "  2.7339589152163337,\n",
       "  2.7357751503779553,\n",
       "  2.7265140906510266,\n",
       "  2.6751143257919785,\n",
       "  2.741438455356352,\n",
       "  2.6888904097804263,\n",
       "  2.7198367959956613,\n",
       "  2.772190352631441,\n",
       "  2.724964616335236,\n",
       "  2.6990280681248233,\n",
       "  2.729297422367479,\n",
       "  2.731698456910109,\n",
       "  2.697100618407001,\n",
       "  2.6893323132973035,\n",
       "  2.7288458497621186,\n",
       "  2.716885070990042,\n",
       "  2.6943486595439903,\n",
       "  2.695336557157111,\n",
       "  2.7025389789752037,\n",
       "  2.720439397969047,\n",
       "  2.678360037041378,\n",
       "  2.6753101984414935,\n",
       "  2.65743655419456,\n",
       "  2.68362051880678,\n",
       "  2.6580661056499455,\n",
       "  2.7227433404511623,\n",
       "  2.6903060327690724,\n",
       "  2.712834693642045,\n",
       "  2.6712819112049018,\n",
       "  2.719255342427264,\n",
       "  2.6854429991399362,\n",
       "  2.6328873502695638,\n",
       "  2.732601814218917,\n",
       "  2.686709600723314,\n",
       "  2.647602455749562,\n",
       "  2.662478561788695,\n",
       "  2.7293581733705015,\n",
       "  2.720677347280803,\n",
       "  2.6828432584437274,\n",
       "  2.6698448547512457,\n",
       "  2.6928480666173993,\n",
       "  2.7530694236498756,\n",
       "  2.7339840303758396,\n",
       "  2.6796955547656363,\n",
       "  2.652990051162951,\n",
       "  2.6914970591686664,\n",
       "  2.654867573160408,\n",
       "  2.709142156151702,\n",
       "  2.6604245788751473,\n",
       "  2.6139519774984197,\n",
       "  2.6963910234867328,\n",
       "  2.714055235348275,\n",
       "  2.669655451921988,\n",
       "  2.619291559353804,\n",
       "  2.6972006735977914,\n",
       "  2.6360400467467326,\n",
       "  2.644187037768199,\n",
       "  2.682317528184462,\n",
       "  2.69127620121051,\n",
       "  2.6849116471420285,\n",
       "  2.634957963135609,\n",
       "  2.689488765086031,\n",
       "  2.6639799099031825,\n",
       "  2.709821814420515,\n",
       "  2.65903219223122,\n",
       "  2.6645072916380323,\n",
       "  2.710836167475704,\n",
       "  2.6956021296163755,\n",
       "  2.6880041294630654,\n",
       "  2.6524575011508125,\n",
       "  2.6818518406937035,\n",
       "  2.721720863136936,\n",
       "  2.654705539878037,\n",
       "  2.6637119884219254],\n",
       " 'model_tr_BPE_vs20000': [3.332771358053102,\n",
       "  3.266880840068074,\n",
       "  3.1631238247587796,\n",
       "  3.0122992958663404,\n",
       "  2.9748301260098002,\n",
       "  2.811170711616759,\n",
       "  2.7940670441264936,\n",
       "  2.799013377003258,\n",
       "  2.7986120927629616,\n",
       "  2.7816976372184974,\n",
       "  2.7266679006641876,\n",
       "  2.7501344020495067,\n",
       "  2.692489172033998,\n",
       "  2.718350048383459,\n",
       "  2.682410941884532,\n",
       "  2.68289358681762,\n",
       "  2.7301058120602533,\n",
       "  2.6392201631294028,\n",
       "  2.683207747142968,\n",
       "  2.639175353674172,\n",
       "  2.615874899751936,\n",
       "  2.614469481770679,\n",
       "  2.6489186253326626,\n",
       "  2.6066417880666384,\n",
       "  2.5889004278135834,\n",
       "  2.5773692482756867,\n",
       "  2.6098502037764586,\n",
       "  2.5823078617225717,\n",
       "  2.5802392796132927,\n",
       "  2.55708760798726,\n",
       "  2.60008809113351,\n",
       "  2.5435523655928005,\n",
       "  2.579991398317612,\n",
       "  2.557412223854357,\n",
       "  2.5652181596382353,\n",
       "  2.5593132593812387,\n",
       "  2.5231274177223497,\n",
       "  2.5516439839628844,\n",
       "  2.586848120504158,\n",
       "  2.5241774401590695,\n",
       "  2.5365697609007736,\n",
       "  2.548411625031241,\n",
       "  2.484505351230865,\n",
       "  2.549635258174162,\n",
       "  2.4861916101525097,\n",
       "  2.4659736636793292,\n",
       "  2.509166848895622,\n",
       "  2.4674622018097407,\n",
       "  2.4908017049040407,\n",
       "  2.5238161411673548,\n",
       "  2.4839362091183133,\n",
       "  2.539485727750102,\n",
       "  2.4692715225662876,\n",
       "  2.4911059079954248,\n",
       "  2.45369167322642,\n",
       "  2.4948577754088777,\n",
       "  2.478980465705457,\n",
       "  2.511388929318459,\n",
       "  2.4868062949000884,\n",
       "  2.4843789540269006,\n",
       "  2.5053137868523336,\n",
       "  2.4889991609235076,\n",
       "  2.4906129871270224,\n",
       "  2.4461023271032905,\n",
       "  2.4629175153526823,\n",
       "  2.460506031399995,\n",
       "  2.506205644724261,\n",
       "  2.461492116863283,\n",
       "  2.4688336629292142,\n",
       "  2.4907004910522295,\n",
       "  2.466559103350395,\n",
       "  2.4818129180755544,\n",
       "  2.4734862015527708,\n",
       "  2.4545123078440523,\n",
       "  2.448429744176515,\n",
       "  2.4551718376655933,\n",
       "  2.425186008187654,\n",
       "  2.421998110161919,\n",
       "  2.4825991820317204,\n",
       "  2.505424034226902,\n",
       "  2.440470291774015,\n",
       "  2.4282565566424203,\n",
       "  2.423381656909567,\n",
       "  2.4846225916101567,\n",
       "  2.456485077481105,\n",
       "  2.452194946498617,\n",
       "  2.441790265239851,\n",
       "  2.4575355104630896,\n",
       "  2.4376271653768784,\n",
       "  2.5075053096486855,\n",
       "  2.4729879381379942,\n",
       "  2.4696668219917246,\n",
       "  2.448362794170559,\n",
       "  2.4479906254441155,\n",
       "  2.4630894488364095,\n",
       "  2.4374528755502762,\n",
       "  2.467137174888064,\n",
       "  2.421223161969933,\n",
       "  2.435967692072346,\n",
       "  2.4311975983029592,\n",
       "  2.425343463443693,\n",
       "  2.4355766467151607,\n",
       "  2.451462492490833,\n",
       "  2.4316591713059803,\n",
       "  2.454565878935367,\n",
       "  2.4889660169776335,\n",
       "  2.478602410037823,\n",
       "  2.424449570161992,\n",
       "  2.404521273200547,\n",
       "  2.444681364007116,\n",
       "  2.4507316432884743,\n",
       "  2.4862142484411645,\n",
       "  2.480580938798812,\n",
       "  2.4831482126156024,\n",
       "  2.449775034003893,\n",
       "  2.457911766973346],\n",
       " 'model_tr_BPE_vs30000': [3.2847229147117107,\n",
       "  3.2461240601618826,\n",
       "  3.0991908658546663,\n",
       "  2.966096561274986,\n",
       "  2.8776907959862736,\n",
       "  2.7770168829983457,\n",
       "  2.695303287563698,\n",
       "  2.692703927016449,\n",
       "  2.649488020992789,\n",
       "  2.6386570697031257,\n",
       "  2.6798487020124324,\n",
       "  2.656371257238182,\n",
       "  2.6340549478788784,\n",
       "  2.620283073646725,\n",
       "  2.613946953552063,\n",
       "  2.5938283191151315,\n",
       "  2.5985632125241227,\n",
       "  2.6175828276765007,\n",
       "  2.550373616085781,\n",
       "  2.588213600617003,\n",
       "  2.5556564576319607,\n",
       "  2.534788927396141,\n",
       "  2.5648026317831403,\n",
       "  2.512257077681238,\n",
       "  2.493457839594915,\n",
       "  2.4980836157104593,\n",
       "  2.580821802284535,\n",
       "  2.4776537816241255,\n",
       "  2.5072372515473655,\n",
       "  2.496280375157422,\n",
       "  2.5074550668107713,\n",
       "  2.486862942729829,\n",
       "  2.52116197900348,\n",
       "  2.5030676115736363,\n",
       "  2.460208403663761,\n",
       "  2.481666932629623,\n",
       "  2.490714942528202,\n",
       "  2.4987152346009616,\n",
       "  2.4934171528279307,\n",
       "  2.468216371117162,\n",
       "  2.4641278635919566,\n",
       "  2.482456110901403,\n",
       "  2.4747065857918407,\n",
       "  2.454863346455637,\n",
       "  2.463449757267277,\n",
       "  2.473513411929927,\n",
       "  2.474201188910619,\n",
       "  2.426169280092198,\n",
       "  2.4527654921680853,\n",
       "  2.460968205427641,\n",
       "  2.4247595718886856,\n",
       "  2.4450125051214817,\n",
       "  2.423563400627532,\n",
       "  2.422974534373892,\n",
       "  2.436384819966982,\n",
       "  2.4147566784483745,\n",
       "  2.420586422041094,\n",
       "  2.4377321304409487,\n",
       "  2.428465420157356,\n",
       "  2.3729290165203816,\n",
       "  2.401355646907297,\n",
       "  2.4581318128390404,\n",
       "  2.4243747435761964,\n",
       "  2.406527305183642,\n",
       "  2.397883412683939,\n",
       "  2.388097582391934,\n",
       "  2.443815344733763,\n",
       "  2.431808055427816,\n",
       "  2.3781878693872636,\n",
       "  2.3939664723294967,\n",
       "  2.4192734555478337,\n",
       "  2.3907060513434857,\n",
       "  2.414747567320108,\n",
       "  2.378028655564848,\n",
       "  2.4048548366275875,\n",
       "  2.397550068379493,\n",
       "  2.380212005827439,\n",
       "  2.3650228698966096,\n",
       "  2.371751591932851,\n",
       "  2.409450308506648,\n",
       "  2.3925234205961265,\n",
       "  2.375928556012606,\n",
       "  2.3700027682299285,\n",
       "  2.379057456680438,\n",
       "  2.403202831577696,\n",
       "  2.4007439345650017,\n",
       "  2.400387811379369,\n",
       "  2.388801213201649,\n",
       "  2.395734670948454,\n",
       "  2.4282462606142845,\n",
       "  2.380565873551703,\n",
       "  2.3761689305998495,\n",
       "  2.373218436639608,\n",
       "  2.398976348128422,\n",
       "  2.376827935732127,\n",
       "  2.401192453593353,\n",
       "  2.389435763119556,\n",
       "  2.3783612407887147,\n",
       "  2.4163391589991003,\n",
       "  2.4010678308188567,\n",
       "  2.36359716255395,\n",
       "  2.3795881862496238,\n",
       "  2.3591521306417977,\n",
       "  2.3921171199027156,\n",
       "  2.3682450059665605,\n",
       "  2.4034925079817677,\n",
       "  2.4052182174421266,\n",
       "  2.379523278132225,\n",
       "  2.3687481794261993,\n",
       "  2.3933654546429275,\n",
       "  2.3800037785668193,\n",
       "  2.3905753203078315,\n",
       "  2.4043354766618155,\n",
       "  2.410312640536386,\n",
       "  2.3803781798859696,\n",
       "  2.3702743139958513],\n",
       " 'model_tr_BPE_vs40000': [3.278958798622009,\n",
       "  3.166921450225667,\n",
       "  3.0818585629527484,\n",
       "  2.9877350755194616,\n",
       "  2.858659561893057,\n",
       "  2.7486265876104654,\n",
       "  2.6776421454477397,\n",
       "  2.6663700912083383,\n",
       "  2.6350868245287895,\n",
       "  2.6293749577302736,\n",
       "  2.607653775971749,\n",
       "  2.5866104802162457,\n",
       "  2.619521059010902,\n",
       "  2.58812879792211,\n",
       "  2.617819564587011,\n",
       "  2.5385381690487034,\n",
       "  2.564943148008769,\n",
       "  2.55755971292296,\n",
       "  2.53385196870201,\n",
       "  2.5011310630960204,\n",
       "  2.507011976504289,\n",
       "  2.5249778900390125,\n",
       "  2.48953519242839,\n",
       "  2.4955551077356013,\n",
       "  2.48358039557331,\n",
       "  2.503150363524696,\n",
       "  2.5124711267641477,\n",
       "  2.4828905205011913,\n",
       "  2.447752612808531,\n",
       "  2.447392637384585,\n",
       "  2.4897855397804927,\n",
       "  2.490129403843404,\n",
       "  2.453775381371849,\n",
       "  2.449947093702162,\n",
       "  2.455067420269469,\n",
       "  2.4611366254019185,\n",
       "  2.485787416223509,\n",
       "  2.429491414475424,\n",
       "  2.4327391407695846,\n",
       "  2.4463617199440075,\n",
       "  2.431645165424359,\n",
       "  2.419571086471725,\n",
       "  2.375438814354354,\n",
       "  2.4141846582360342,\n",
       "  2.4242350613582504,\n",
       "  2.4063819457950966,\n",
       "  2.437013886466725,\n",
       "  2.385827078894749,\n",
       "  2.4062306872510932,\n",
       "  2.423519304460192,\n",
       "  2.3726369117012345,\n",
       "  2.420564295400371,\n",
       "  2.3835229095911576,\n",
       "  2.377240416420933,\n",
       "  2.4090313227320856,\n",
       "  2.3631917184850217,\n",
       "  2.3852889756172058,\n",
       "  2.3787418652522985,\n",
       "  2.365217263912654,\n",
       "  2.347687161830677,\n",
       "  2.363412026735295,\n",
       "  2.382978506339237,\n",
       "  2.3826981386120507,\n",
       "  2.327388313929555,\n",
       "  2.3304069629711406,\n",
       "  2.375260042423625,\n",
       "  2.3514721827755927,\n",
       "  2.390414086003152,\n",
       "  2.360631917134714,\n",
       "  2.4084912144223525,\n",
       "  2.3720339471513787,\n",
       "  2.389083056804594,\n",
       "  2.3596083438376274,\n",
       "  2.3583871770690585,\n",
       "  2.377106135609592,\n",
       "  2.349420999705559,\n",
       "  2.3516849785571368,\n",
       "  2.3341407603913717,\n",
       "  2.3603919143807324,\n",
       "  2.36071562426258,\n",
       "  2.3434988905998324,\n",
       "  2.3577432872508117,\n",
       "  2.36082772749297,\n",
       "  2.4028297179484572,\n",
       "  2.3827026570187533,\n",
       "  2.345507619125453,\n",
       "  2.346013616887515,\n",
       "  2.3488220277884264,\n",
       "  2.371759014897137,\n",
       "  2.393500376170597,\n",
       "  2.3242214382996726,\n",
       "  2.360190826277288,\n",
       "  2.3524273954530557,\n",
       "  2.3320707105347047,\n",
       "  2.3121964803340522,\n",
       "  2.3176486600207094,\n",
       "  2.3398862789805044,\n",
       "  2.3469824509434334,\n",
       "  2.347200040576326,\n",
       "  2.3575884090413473,\n",
       "  2.3324793360237934,\n",
       "  2.3312832424600844,\n",
       "  2.3180320310554148,\n",
       "  2.3387448040000827,\n",
       "  2.3293562245629196,\n",
       "  2.3744619647996092,\n",
       "  2.3242563843489483,\n",
       "  2.3565753749690574,\n",
       "  2.35681032155344,\n",
       "  2.3388055589021306,\n",
       "  2.3308277430873914,\n",
       "  2.312518575173854,\n",
       "  2.3612489436938446,\n",
       "  2.3876926691067424,\n",
       "  2.3239208415884396,\n",
       "  2.323380098558577]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpc_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ALL_MODELS_FOLDER + 'model_es_BPE_vs10000/checkpoint-583/trainer_state.json', \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 0.008576329331046312,\n",
       "  'grad_norm': 14.54792308807373,\n",
       "  'learning_rate': 8.333333333333333e-05,\n",
       "  'loss': 9.2037,\n",
       "  'step': 5},\n",
       " {'epoch': 0.008576329331046312,\n",
       "  'eval_bpc': 3.9953058180117345,\n",
       "  'eval_loss': 9.072009086608887,\n",
       "  'eval_perplexity': 8705.6943359375,\n",
       "  'eval_runtime': 10.423,\n",
       "  'eval_samples_per_second': 245.61,\n",
       "  'eval_steps_per_second': 3.838,\n",
       "  'step': 5},\n",
       " {'epoch': 0.017152658662092625,\n",
       "  'grad_norm': 12.351099014282227,\n",
       "  'learning_rate': 0.00016666666666666666,\n",
       "  'loss': 8.9551,\n",
       "  'step': 10},\n",
       " {'epoch': 0.017152658662092625,\n",
       "  'eval_bpc': 3.815965256450828,\n",
       "  'eval_loss': 8.755976676940918,\n",
       "  'eval_perplexity': 6166.81787109375,\n",
       "  'eval_runtime': 10.3346,\n",
       "  'eval_samples_per_second': 247.712,\n",
       "  'eval_steps_per_second': 3.871,\n",
       "  'step': 10},\n",
       " {'epoch': 0.025728987993138937,\n",
       "  'grad_norm': 12.194334983825684,\n",
       "  'learning_rate': 0.00025,\n",
       "  'loss': 8.633,\n",
       "  'step': 15},\n",
       " {'epoch': 0.025728987993138937,\n",
       "  'eval_bpc': 3.6624676062772807,\n",
       "  'eval_loss': 8.410711288452148,\n",
       "  'eval_perplexity': 4455.67822265625,\n",
       "  'eval_runtime': 10.4492,\n",
       "  'eval_samples_per_second': 244.995,\n",
       "  'eval_steps_per_second': 3.828,\n",
       "  'step': 15},\n",
       " {'epoch': 0.03430531732418525,\n",
       "  'grad_norm': 12.2364501953125,\n",
       "  'learning_rate': 0.0003333333333333333,\n",
       "  'loss': 8.2505,\n",
       "  'step': 20},\n",
       " {'epoch': 0.03430531732418525,\n",
       "  'eval_bpc': 3.481875157404405,\n",
       "  'eval_loss': 7.988757133483887,\n",
       "  'eval_perplexity': 2951.245849609375,\n",
       "  'eval_runtime': 10.3149,\n",
       "  'eval_samples_per_second': 248.185,\n",
       "  'eval_steps_per_second': 3.878,\n",
       "  'step': 20},\n",
       " {'epoch': 0.04288164665523156,\n",
       "  'grad_norm': 11.34581184387207,\n",
       "  'learning_rate': 0.0004166666666666667,\n",
       "  'loss': 7.8175,\n",
       "  'step': 25},\n",
       " {'epoch': 0.04288164665523156,\n",
       "  'eval_bpc': 3.315451010890085,\n",
       "  'eval_loss': 7.539826393127441,\n",
       "  'eval_perplexity': 1834.620849609375,\n",
       "  'eval_runtime': 10.4571,\n",
       "  'eval_samples_per_second': 244.81,\n",
       "  'eval_steps_per_second': 3.825,\n",
       "  'step': 25},\n",
       " {'epoch': 0.051457975986277875,\n",
       "  'grad_norm': 9.656057357788086,\n",
       "  'learning_rate': 0.0005,\n",
       "  'loss': 7.3862,\n",
       "  'step': 30},\n",
       " {'epoch': 0.051457975986277875,\n",
       "  'eval_bpc': 3.0786520799016173,\n",
       "  'eval_loss': 7.1674065589904785,\n",
       "  'eval_perplexity': 1278.8592529296875,\n",
       "  'eval_runtime': 10.4157,\n",
       "  'eval_samples_per_second': 245.783,\n",
       "  'eval_steps_per_second': 3.84,\n",
       "  'step': 30},\n",
       " {'epoch': 0.060034305317324184,\n",
       "  'grad_norm': 5.978090286254883,\n",
       "  'learning_rate': 0.0004954792043399638,\n",
       "  'loss': 7.0568,\n",
       "  'step': 35},\n",
       " {'epoch': 0.060034305317324184,\n",
       "  'eval_bpc': 3.0615162639338633,\n",
       "  'eval_loss': 6.927256107330322,\n",
       "  'eval_perplexity': 984.6068725585938,\n",
       "  'eval_runtime': 10.3924,\n",
       "  'eval_samples_per_second': 246.334,\n",
       "  'eval_steps_per_second': 3.849,\n",
       "  'step': 35},\n",
       " {'epoch': 0.0686106346483705,\n",
       "  'grad_norm': 1.688528060913086,\n",
       "  'learning_rate': 0.0004909584086799277,\n",
       "  'loss': 6.8718,\n",
       "  'step': 40},\n",
       " {'epoch': 0.0686106346483705,\n",
       "  'eval_bpc': 2.991322781436518,\n",
       "  'eval_loss': 6.852288246154785,\n",
       "  'eval_perplexity': 938.639892578125,\n",
       "  'eval_runtime': 10.3675,\n",
       "  'eval_samples_per_second': 246.926,\n",
       "  'eval_steps_per_second': 3.858,\n",
       "  'step': 40},\n",
       " {'epoch': 0.07718696397941681,\n",
       "  'grad_norm': 1.9380755424499512,\n",
       "  'learning_rate': 0.0004864376130198915,\n",
       "  'loss': 6.8346,\n",
       "  'step': 45},\n",
       " {'epoch': 0.07718696397941681,\n",
       "  'eval_bpc': 2.9219343985406874,\n",
       "  'eval_loss': 6.812242031097412,\n",
       "  'eval_perplexity': 934.01220703125,\n",
       "  'eval_runtime': 10.4324,\n",
       "  'eval_samples_per_second': 245.389,\n",
       "  'eval_steps_per_second': 3.834,\n",
       "  'step': 45},\n",
       " {'epoch': 0.08576329331046312,\n",
       "  'grad_norm': 4.8418989181518555,\n",
       "  'learning_rate': 0.0004819168173598553,\n",
       "  'loss': 6.7884,\n",
       "  'step': 50},\n",
       " {'epoch': 0.08576329331046312,\n",
       "  'eval_bpc': 2.9342840626559132,\n",
       "  'eval_loss': 6.7864484786987305,\n",
       "  'eval_perplexity': 901.7179565429688,\n",
       "  'eval_runtime': 10.4407,\n",
       "  'eval_samples_per_second': 245.195,\n",
       "  'eval_steps_per_second': 3.831,\n",
       "  'step': 50},\n",
       " {'epoch': 0.09433962264150944,\n",
       "  'grad_norm': 3.2035939693450928,\n",
       "  'learning_rate': 0.0004773960216998192,\n",
       "  'loss': 6.7489,\n",
       "  'step': 55},\n",
       " {'epoch': 0.09433962264150944,\n",
       "  'eval_bpc': 2.920990074048429,\n",
       "  'eval_loss': 6.7524261474609375,\n",
       "  'eval_perplexity': 855.0648193359375,\n",
       "  'eval_runtime': 10.3565,\n",
       "  'eval_samples_per_second': 247.187,\n",
       "  'eval_steps_per_second': 3.862,\n",
       "  'step': 55},\n",
       " {'epoch': 0.10291595197255575,\n",
       "  'grad_norm': 2.214787006378174,\n",
       "  'learning_rate': 0.000472875226039783,\n",
       "  'loss': 6.6906,\n",
       "  'step': 60},\n",
       " {'epoch': 0.10291595197255575,\n",
       "  'eval_bpc': 2.8923648238112234,\n",
       "  'eval_loss': 6.699849605560303,\n",
       "  'eval_perplexity': 783.825927734375,\n",
       "  'eval_runtime': 10.4615,\n",
       "  'eval_samples_per_second': 244.706,\n",
       "  'eval_steps_per_second': 3.824,\n",
       "  'step': 60},\n",
       " {'epoch': 0.11149228130360206,\n",
       "  'grad_norm': 2.3310811519622803,\n",
       "  'learning_rate': 0.00046835443037974685,\n",
       "  'loss': 6.6589,\n",
       "  'step': 65},\n",
       " {'epoch': 0.11149228130360206,\n",
       "  'eval_bpc': 2.9088227385815504,\n",
       "  'eval_loss': 6.64272928237915,\n",
       "  'eval_perplexity': 760.4843139648438,\n",
       "  'eval_runtime': 10.9253,\n",
       "  'eval_samples_per_second': 234.319,\n",
       "  'eval_steps_per_second': 3.661,\n",
       "  'step': 65},\n",
       " {'epoch': 0.12006861063464837,\n",
       "  'grad_norm': 2.0196332931518555,\n",
       "  'learning_rate': 0.0004638336347197107,\n",
       "  'loss': 6.6153,\n",
       "  'step': 70},\n",
       " {'epoch': 0.12006861063464837,\n",
       "  'eval_bpc': 2.8587452818780017,\n",
       "  'eval_loss': 6.6015944480896,\n",
       "  'eval_perplexity': 705.3020629882812,\n",
       "  'eval_runtime': 10.4305,\n",
       "  'eval_samples_per_second': 245.434,\n",
       "  'eval_steps_per_second': 3.835,\n",
       "  'step': 70},\n",
       " {'epoch': 0.12864493996569468,\n",
       "  'grad_norm': 2.0128180980682373,\n",
       "  'learning_rate': 0.0004593128390596745,\n",
       "  'loss': 6.5836,\n",
       "  'step': 75},\n",
       " {'epoch': 0.12864493996569468,\n",
       "  'eval_bpc': 2.831865208228805,\n",
       "  'eval_loss': 6.566880702972412,\n",
       "  'eval_perplexity': 690.9374389648438,\n",
       "  'eval_runtime': 10.424,\n",
       "  'eval_samples_per_second': 245.587,\n",
       "  'eval_steps_per_second': 3.837,\n",
       "  'step': 75},\n",
       " {'epoch': 0.137221269296741,\n",
       "  'grad_norm': 2.3361339569091797,\n",
       "  'learning_rate': 0.00045479204339963835,\n",
       "  'loss': 6.5455,\n",
       "  'step': 80},\n",
       " {'epoch': 0.137221269296741,\n",
       "  'eval_bpc': 2.8834524070248495,\n",
       "  'eval_loss': 6.525459289550781,\n",
       "  'eval_perplexity': 647.3030395507812,\n",
       "  'eval_runtime': 10.3821,\n",
       "  'eval_samples_per_second': 246.579,\n",
       "  'eval_steps_per_second': 3.853,\n",
       "  'step': 80},\n",
       " {'epoch': 0.1457975986277873,\n",
       "  'grad_norm': 2.2184062004089355,\n",
       "  'learning_rate': 0.00045027124773960213,\n",
       "  'loss': 6.5158,\n",
       "  'step': 85},\n",
       " {'epoch': 0.1457975986277873,\n",
       "  'eval_bpc': 2.7975733162665746,\n",
       "  'eval_loss': 6.501979827880859,\n",
       "  'eval_perplexity': 623.9983520507812,\n",
       "  'eval_runtime': 10.3759,\n",
       "  'eval_samples_per_second': 246.725,\n",
       "  'eval_steps_per_second': 3.855,\n",
       "  'step': 85},\n",
       " {'epoch': 0.15437392795883362,\n",
       "  'grad_norm': 2.1338188648223877,\n",
       "  'learning_rate': 0.00044575045207956597,\n",
       "  'loss': 6.4752,\n",
       "  'step': 90},\n",
       " {'epoch': 0.15437392795883362,\n",
       "  'eval_bpc': 2.8040014855765003,\n",
       "  'eval_loss': 6.46768045425415,\n",
       "  'eval_perplexity': 621.5892944335938,\n",
       "  'eval_runtime': 10.416,\n",
       "  'eval_samples_per_second': 245.775,\n",
       "  'eval_steps_per_second': 3.84,\n",
       "  'step': 90},\n",
       " {'epoch': 0.16295025728987994,\n",
       "  'grad_norm': 2.1822500228881836,\n",
       "  'learning_rate': 0.00044122965641952986,\n",
       "  'loss': 6.4548,\n",
       "  'step': 95},\n",
       " {'epoch': 0.16295025728987994,\n",
       "  'eval_bpc': 2.8111562262478,\n",
       "  'eval_loss': 6.449045658111572,\n",
       "  'eval_perplexity': 619.0277709960938,\n",
       "  'eval_runtime': 10.4292,\n",
       "  'eval_samples_per_second': 245.466,\n",
       "  'eval_steps_per_second': 3.835,\n",
       "  'step': 95},\n",
       " {'epoch': 0.17152658662092624,\n",
       "  'grad_norm': 3.0343246459960938,\n",
       "  'learning_rate': 0.0004367088607594937,\n",
       "  'loss': 6.4381,\n",
       "  'step': 100},\n",
       " {'epoch': 0.17152658662092624,\n",
       "  'eval_bpc': 2.7733700315133722,\n",
       "  'eval_loss': 6.411386966705322,\n",
       "  'eval_perplexity': 614.9539794921875,\n",
       "  'eval_runtime': 10.4259,\n",
       "  'eval_samples_per_second': 245.543,\n",
       "  'eval_steps_per_second': 3.837,\n",
       "  'step': 100},\n",
       " {'epoch': 0.18010291595197256,\n",
       "  'grad_norm': 3.515859603881836,\n",
       "  'learning_rate': 0.0004321880650994575,\n",
       "  'loss': 6.4051,\n",
       "  'step': 105},\n",
       " {'epoch': 0.18010291595197256,\n",
       "  'eval_bpc': 2.757835074782902,\n",
       "  'eval_loss': 6.393002033233643,\n",
       "  'eval_perplexity': 617.0794067382812,\n",
       "  'eval_runtime': 10.3799,\n",
       "  'eval_samples_per_second': 246.63,\n",
       "  'eval_steps_per_second': 3.854,\n",
       "  'step': 105},\n",
       " {'epoch': 0.18867924528301888,\n",
       "  'grad_norm': 2.050340175628662,\n",
       "  'learning_rate': 0.00042766726943942136,\n",
       "  'loss': 6.3801,\n",
       "  'step': 110},\n",
       " {'epoch': 0.18867924528301888,\n",
       "  'eval_bpc': 2.768960140978562,\n",
       "  'eval_loss': 6.381384372711182,\n",
       "  'eval_perplexity': 576.8551025390625,\n",
       "  'eval_runtime': 10.5002,\n",
       "  'eval_samples_per_second': 243.804,\n",
       "  'eval_steps_per_second': 3.809,\n",
       "  'step': 110},\n",
       " {'epoch': 0.19725557461406518,\n",
       "  'grad_norm': 1.9393913745880127,\n",
       "  'learning_rate': 0.0004231464737793852,\n",
       "  'loss': 6.3595,\n",
       "  'step': 115},\n",
       " {'epoch': 0.19725557461406518,\n",
       "  'eval_bpc': 2.73191926615214,\n",
       "  'eval_loss': 6.356963157653809,\n",
       "  'eval_perplexity': 571.047607421875,\n",
       "  'eval_runtime': 10.3202,\n",
       "  'eval_samples_per_second': 248.057,\n",
       "  'eval_steps_per_second': 3.876,\n",
       "  'step': 115},\n",
       " {'epoch': 0.2058319039451115,\n",
       "  'grad_norm': 2.143104076385498,\n",
       "  'learning_rate': 0.00041862567811934903,\n",
       "  'loss': 6.3562,\n",
       "  'step': 120},\n",
       " {'epoch': 0.2058319039451115,\n",
       "  'eval_bpc': 2.769781908432716,\n",
       "  'eval_loss': 6.357357025146484,\n",
       "  'eval_perplexity': 575.7850341796875,\n",
       "  'eval_runtime': 10.3726,\n",
       "  'eval_samples_per_second': 246.803,\n",
       "  'eval_steps_per_second': 3.856,\n",
       "  'step': 120},\n",
       " {'epoch': 0.2144082332761578,\n",
       "  'grad_norm': 2.4337921142578125,\n",
       "  'learning_rate': 0.0004141048824593128,\n",
       "  'loss': 6.3314,\n",
       "  'step': 125},\n",
       " {'epoch': 0.2144082332761578,\n",
       "  'eval_bpc': 2.728348755105268,\n",
       "  'eval_loss': 6.340982913970947,\n",
       "  'eval_perplexity': 556.7474365234375,\n",
       "  'eval_runtime': 10.2679,\n",
       "  'eval_samples_per_second': 249.322,\n",
       "  'eval_steps_per_second': 3.896,\n",
       "  'step': 125},\n",
       " {'epoch': 0.22298456260720412,\n",
       "  'grad_norm': 2.521066427230835,\n",
       "  'learning_rate': 0.00040958408679927664,\n",
       "  'loss': 6.3397,\n",
       "  'step': 130},\n",
       " {'epoch': 0.22298456260720412,\n",
       "  'eval_bpc': 2.7338062432001213,\n",
       "  'eval_loss': 6.317538261413574,\n",
       "  'eval_perplexity': 538.9574584960938,\n",
       "  'eval_runtime': 10.3601,\n",
       "  'eval_samples_per_second': 247.101,\n",
       "  'eval_steps_per_second': 3.861,\n",
       "  'step': 130},\n",
       " {'epoch': 0.23156089193825044,\n",
       "  'grad_norm': 2.16733717918396,\n",
       "  'learning_rate': 0.00040506329113924053,\n",
       "  'loss': 6.3082,\n",
       "  'step': 135},\n",
       " {'epoch': 0.23156089193825044,\n",
       "  'eval_bpc': 2.734358180148394,\n",
       "  'eval_loss': 6.3167009353637695,\n",
       "  'eval_perplexity': 584.6278076171875,\n",
       "  'eval_runtime': 10.2484,\n",
       "  'eval_samples_per_second': 249.794,\n",
       "  'eval_steps_per_second': 3.903,\n",
       "  'step': 135},\n",
       " {'epoch': 0.24013722126929674,\n",
       "  'grad_norm': 2.1097254753112793,\n",
       "  'learning_rate': 0.00040054249547920437,\n",
       "  'loss': 6.2807,\n",
       "  'step': 140},\n",
       " {'epoch': 0.24013722126929674,\n",
       "  'eval_bpc': 2.7231005502507446,\n",
       "  'eval_loss': 6.301109790802002,\n",
       "  'eval_perplexity': 541.113037109375,\n",
       "  'eval_runtime': 10.2963,\n",
       "  'eval_samples_per_second': 248.634,\n",
       "  'eval_steps_per_second': 3.885,\n",
       "  'step': 140},\n",
       " {'epoch': 0.24871355060034306,\n",
       "  'grad_norm': 2.293642997741699,\n",
       "  'learning_rate': 0.0003960216998191682,\n",
       "  'loss': 6.2892,\n",
       "  'step': 145},\n",
       " {'epoch': 0.24871355060034306,\n",
       "  'eval_bpc': 2.7593194678475075,\n",
       "  'eval_loss': 6.280749320983887,\n",
       "  'eval_perplexity': 525.217529296875,\n",
       "  'eval_runtime': 10.2441,\n",
       "  'eval_samples_per_second': 249.899,\n",
       "  'eval_steps_per_second': 3.905,\n",
       "  'step': 145},\n",
       " {'epoch': 0.25728987993138935,\n",
       "  'grad_norm': 2.32200288772583,\n",
       "  'learning_rate': 0.00039150090415913203,\n",
       "  'loss': 6.2686,\n",
       "  'step': 150},\n",
       " {'epoch': 0.25728987993138935,\n",
       "  'eval_bpc': 2.695736842111602,\n",
       "  'eval_loss': 6.284371852874756,\n",
       "  'eval_perplexity': 562.3410034179688,\n",
       "  'eval_runtime': 10.6102,\n",
       "  'eval_samples_per_second': 241.277,\n",
       "  'eval_steps_per_second': 3.77,\n",
       "  'step': 150},\n",
       " {'epoch': 0.2658662092624357,\n",
       "  'grad_norm': 2.2802538871765137,\n",
       "  'learning_rate': 0.00038698010849909587,\n",
       "  'loss': 6.2735,\n",
       "  'step': 155},\n",
       " {'epoch': 0.2658662092624357,\n",
       "  'eval_bpc': 2.7494148338223803,\n",
       "  'eval_loss': 6.281108856201172,\n",
       "  'eval_perplexity': 510.6962890625,\n",
       "  'eval_runtime': 10.2408,\n",
       "  'eval_samples_per_second': 249.979,\n",
       "  'eval_steps_per_second': 3.906,\n",
       "  'step': 155},\n",
       " {'epoch': 0.274442538593482,\n",
       "  'grad_norm': 2.603576898574829,\n",
       "  'learning_rate': 0.00038245931283905965,\n",
       "  'loss': 6.2555,\n",
       "  'step': 160},\n",
       " {'epoch': 0.274442538593482,\n",
       "  'eval_bpc': 2.709901806599649,\n",
       "  'eval_loss': 6.26413106918335,\n",
       "  'eval_perplexity': 510.685546875,\n",
       "  'eval_runtime': 10.3651,\n",
       "  'eval_samples_per_second': 246.984,\n",
       "  'eval_steps_per_second': 3.859,\n",
       "  'step': 160},\n",
       " {'epoch': 0.2830188679245283,\n",
       "  'grad_norm': 2.462952136993408,\n",
       "  'learning_rate': 0.0003779385171790235,\n",
       "  'loss': 6.2401,\n",
       "  'step': 165},\n",
       " {'epoch': 0.2830188679245283,\n",
       "  'eval_bpc': 2.7272720019433665,\n",
       "  'eval_loss': 6.271169185638428,\n",
       "  'eval_perplexity': 546.1166381835938,\n",
       "  'eval_runtime': 10.2841,\n",
       "  'eval_samples_per_second': 248.927,\n",
       "  'eval_steps_per_second': 3.889,\n",
       "  'step': 165},\n",
       " {'epoch': 0.2915951972555746,\n",
       "  'grad_norm': 2.3544583320617676,\n",
       "  'learning_rate': 0.0003734177215189873,\n",
       "  'loss': 6.2561,\n",
       "  'step': 170},\n",
       " {'epoch': 0.2915951972555746,\n",
       "  'eval_bpc': 2.7156565129203374,\n",
       "  'eval_loss': 6.238469123840332,\n",
       "  'eval_perplexity': 503.01580810546875,\n",
       "  'eval_runtime': 10.2948,\n",
       "  'eval_samples_per_second': 248.669,\n",
       "  'eval_steps_per_second': 3.885,\n",
       "  'step': 170},\n",
       " {'epoch': 0.30017152658662094,\n",
       "  'grad_norm': 2.586740255355835,\n",
       "  'learning_rate': 0.0003688969258589512,\n",
       "  'loss': 6.236,\n",
       "  'step': 175},\n",
       " {'epoch': 0.30017152658662094,\n",
       "  'eval_bpc': 2.7293385863560506,\n",
       "  'eval_loss': 6.22914981842041,\n",
       "  'eval_perplexity': 512.7319946289062,\n",
       "  'eval_runtime': 10.3441,\n",
       "  'eval_samples_per_second': 247.483,\n",
       "  'eval_steps_per_second': 3.867,\n",
       "  'step': 175},\n",
       " {'epoch': 0.30874785591766724,\n",
       "  'grad_norm': 2.574430227279663,\n",
       "  'learning_rate': 0.00036437613019891504,\n",
       "  'loss': 6.2345,\n",
       "  'step': 180},\n",
       " {'epoch': 0.30874785591766724,\n",
       "  'eval_bpc': 2.763826265201652,\n",
       "  'eval_loss': 6.226694583892822,\n",
       "  'eval_perplexity': 539.2682495117188,\n",
       "  'eval_runtime': 10.2321,\n",
       "  'eval_samples_per_second': 250.193,\n",
       "  'eval_steps_per_second': 3.909,\n",
       "  'step': 180},\n",
       " {'epoch': 0.31732418524871353,\n",
       "  'grad_norm': 2.985792636871338,\n",
       "  'learning_rate': 0.0003598553345388789,\n",
       "  'loss': 6.2232,\n",
       "  'step': 185},\n",
       " {'epoch': 0.31732418524871353,\n",
       "  'eval_bpc': 2.68039728174644,\n",
       "  'eval_loss': 6.227916717529297,\n",
       "  'eval_perplexity': 510.18658447265625,\n",
       "  'eval_runtime': 10.1818,\n",
       "  'eval_samples_per_second': 251.428,\n",
       "  'eval_steps_per_second': 3.929,\n",
       "  'step': 185},\n",
       " {'epoch': 0.3259005145797599,\n",
       "  'grad_norm': 2.9537668228149414,\n",
       "  'learning_rate': 0.0003553345388788427,\n",
       "  'loss': 6.2008,\n",
       "  'step': 190},\n",
       " {'epoch': 0.3259005145797599,\n",
       "  'eval_bpc': 2.7158696393102053,\n",
       "  'eval_loss': 6.212029457092285,\n",
       "  'eval_perplexity': 493.8455505371094,\n",
       "  'eval_runtime': 10.2575,\n",
       "  'eval_samples_per_second': 249.573,\n",
       "  'eval_steps_per_second': 3.9,\n",
       "  'step': 190},\n",
       " {'epoch': 0.3344768439108062,\n",
       "  'grad_norm': 2.4739015102386475,\n",
       "  'learning_rate': 0.0003508137432188065,\n",
       "  'loss': 6.2219,\n",
       "  'step': 195},\n",
       " {'epoch': 0.3344768439108062,\n",
       "  'eval_bpc': 2.753272422638411,\n",
       "  'eval_loss': 6.196679592132568,\n",
       "  'eval_perplexity': 551.487548828125,\n",
       "  'eval_runtime': 10.2909,\n",
       "  'eval_samples_per_second': 248.763,\n",
       "  'eval_steps_per_second': 3.887,\n",
       "  'step': 195},\n",
       " {'epoch': 0.34305317324185247,\n",
       "  'grad_norm': 2.0650665760040283,\n",
       "  'learning_rate': 0.0003462929475587703,\n",
       "  'loss': 6.2132,\n",
       "  'step': 200},\n",
       " {'epoch': 0.34305317324185247,\n",
       "  'eval_bpc': 2.68973129989913,\n",
       "  'eval_loss': 6.200557708740234,\n",
       "  'eval_perplexity': 458.6381530761719,\n",
       "  'eval_runtime': 10.1813,\n",
       "  'eval_samples_per_second': 251.44,\n",
       "  'eval_steps_per_second': 3.929,\n",
       "  'step': 200},\n",
       " {'epoch': 0.3516295025728988,\n",
       "  'grad_norm': 3.383941888809204,\n",
       "  'learning_rate': 0.00034177215189873416,\n",
       "  'loss': 6.2301,\n",
       "  'step': 205},\n",
       " {'epoch': 0.3516295025728988,\n",
       "  'eval_bpc': 2.695348935977371,\n",
       "  'eval_loss': 6.199794769287109,\n",
       "  'eval_perplexity': 502.1724548339844,\n",
       "  'eval_runtime': 10.2261,\n",
       "  'eval_samples_per_second': 250.34,\n",
       "  'eval_steps_per_second': 3.912,\n",
       "  'step': 205},\n",
       " {'epoch': 0.3602058319039451,\n",
       "  'grad_norm': 2.1687917709350586,\n",
       "  'learning_rate': 0.000337251356238698,\n",
       "  'loss': 6.1948,\n",
       "  'step': 210},\n",
       " {'epoch': 0.3602058319039451,\n",
       "  'eval_bpc': 2.733073509204307,\n",
       "  'eval_loss': 6.189632415771484,\n",
       "  'eval_perplexity': 501.4852294921875,\n",
       "  'eval_runtime': 10.4326,\n",
       "  'eval_samples_per_second': 245.385,\n",
       "  'eval_steps_per_second': 3.834,\n",
       "  'step': 210},\n",
       " {'epoch': 0.3687821612349914,\n",
       "  'grad_norm': 3.632984161376953,\n",
       "  'learning_rate': 0.0003327305605786619,\n",
       "  'loss': 6.1768,\n",
       "  'step': 215},\n",
       " {'epoch': 0.3687821612349914,\n",
       "  'eval_bpc': 2.74277574325526,\n",
       "  'eval_loss': 6.192211151123047,\n",
       "  'eval_perplexity': 507.142578125,\n",
       "  'eval_runtime': 10.3336,\n",
       "  'eval_samples_per_second': 247.736,\n",
       "  'eval_steps_per_second': 3.871,\n",
       "  'step': 215},\n",
       " {'epoch': 0.37735849056603776,\n",
       "  'grad_norm': 2.532747507095337,\n",
       "  'learning_rate': 0.0003282097649186257,\n",
       "  'loss': 6.1924,\n",
       "  'step': 220},\n",
       " {'epoch': 0.37735849056603776,\n",
       "  'eval_bpc': 2.6612346010851176,\n",
       "  'eval_loss': 6.1711907386779785,\n",
       "  'eval_perplexity': 456.6370849609375,\n",
       "  'eval_runtime': 10.2544,\n",
       "  'eval_samples_per_second': 249.649,\n",
       "  'eval_steps_per_second': 3.901,\n",
       "  'step': 220},\n",
       " {'epoch': 0.38593481989708406,\n",
       "  'grad_norm': 3.366222381591797,\n",
       "  'learning_rate': 0.00032368896925858955,\n",
       "  'loss': 6.1781,\n",
       "  'step': 225},\n",
       " {'epoch': 0.38593481989708406,\n",
       "  'eval_bpc': 2.6915696649563388,\n",
       "  'eval_loss': 6.167226314544678,\n",
       "  'eval_perplexity': 499.5913391113281,\n",
       "  'eval_runtime': 10.23,\n",
       "  'eval_samples_per_second': 250.244,\n",
       "  'eval_steps_per_second': 3.91,\n",
       "  'step': 225},\n",
       " {'epoch': 0.39451114922813035,\n",
       "  'grad_norm': 3.6790149211883545,\n",
       "  'learning_rate': 0.0003191681735985534,\n",
       "  'loss': 6.185,\n",
       "  'step': 230},\n",
       " {'epoch': 0.39451114922813035,\n",
       "  'eval_bpc': 2.708089475270436,\n",
       "  'eval_loss': 6.166464805603027,\n",
       "  'eval_perplexity': 498.25738525390625,\n",
       "  'eval_runtime': 10.1332,\n",
       "  'eval_samples_per_second': 252.635,\n",
       "  'eval_steps_per_second': 3.947,\n",
       "  'step': 230},\n",
       " {'epoch': 0.40308747855917665,\n",
       "  'grad_norm': 3.8440353870391846,\n",
       "  'learning_rate': 0.00031464737793851716,\n",
       "  'loss': 6.1712,\n",
       "  'step': 235},\n",
       " {'epoch': 0.40308747855917665,\n",
       "  'eval_bpc': 2.684374403187392,\n",
       "  'eval_loss': 6.170886993408203,\n",
       "  'eval_perplexity': 525.89794921875,\n",
       "  'eval_runtime': 10.1312,\n",
       "  'eval_samples_per_second': 252.685,\n",
       "  'eval_steps_per_second': 3.948,\n",
       "  'step': 235},\n",
       " {'epoch': 0.411663807890223,\n",
       "  'grad_norm': 3.8411450386047363,\n",
       "  'learning_rate': 0.000310126582278481,\n",
       "  'loss': 6.1775,\n",
       "  'step': 240},\n",
       " {'epoch': 0.411663807890223,\n",
       "  'eval_bpc': 2.6956457511260514,\n",
       "  'eval_loss': 6.158902168273926,\n",
       "  'eval_perplexity': 453.9058837890625,\n",
       "  'eval_runtime': 10.1804,\n",
       "  'eval_samples_per_second': 251.464,\n",
       "  'eval_steps_per_second': 3.929,\n",
       "  'step': 240},\n",
       " {'epoch': 0.4202401372212693,\n",
       "  'grad_norm': 2.693094253540039,\n",
       "  'learning_rate': 0.00030560578661844483,\n",
       "  'loss': 6.1795,\n",
       "  'step': 245},\n",
       " {'epoch': 0.4202401372212693,\n",
       "  'eval_bpc': 2.7054502866368746,\n",
       "  'eval_loss': 6.147014141082764,\n",
       "  'eval_perplexity': 461.6141662597656,\n",
       "  'eval_runtime': 10.2491,\n",
       "  'eval_samples_per_second': 249.777,\n",
       "  'eval_steps_per_second': 3.903,\n",
       "  'step': 245},\n",
       " {'epoch': 0.4288164665523156,\n",
       "  'grad_norm': 1.9496965408325195,\n",
       "  'learning_rate': 0.00030108499095840867,\n",
       "  'loss': 6.1686,\n",
       "  'step': 250},\n",
       " {'epoch': 0.4288164665523156,\n",
       "  'eval_bpc': 2.6853188234987706,\n",
       "  'eval_loss': 6.155513763427734,\n",
       "  'eval_perplexity': 470.21795654296875,\n",
       "  'eval_runtime': 10.2031,\n",
       "  'eval_samples_per_second': 250.904,\n",
       "  'eval_steps_per_second': 3.92,\n",
       "  'step': 250},\n",
       " {'epoch': 0.43739279588336194,\n",
       "  'grad_norm': 2.276270627975464,\n",
       "  'learning_rate': 0.00029656419529837256,\n",
       "  'loss': 6.1605,\n",
       "  'step': 255},\n",
       " {'epoch': 0.43739279588336194,\n",
       "  'eval_bpc': 2.668947997418598,\n",
       "  'eval_loss': 6.148704528808594,\n",
       "  'eval_perplexity': 469.9532470703125,\n",
       "  'eval_runtime': 10.229,\n",
       "  'eval_samples_per_second': 250.269,\n",
       "  'eval_steps_per_second': 3.91,\n",
       "  'step': 255},\n",
       " {'epoch': 0.44596912521440824,\n",
       "  'grad_norm': 6.734357833862305,\n",
       "  'learning_rate': 0.0002920433996383364,\n",
       "  'loss': 6.1448,\n",
       "  'step': 260},\n",
       " {'epoch': 0.44596912521440824,\n",
       "  'eval_bpc': 2.669865451807563,\n",
       "  'eval_loss': 6.141587257385254,\n",
       "  'eval_perplexity': 455.5399169921875,\n",
       "  'eval_runtime': 10.1279,\n",
       "  'eval_samples_per_second': 252.767,\n",
       "  'eval_steps_per_second': 3.949,\n",
       "  'step': 260},\n",
       " {'epoch': 0.45454545454545453,\n",
       "  'grad_norm': 7.387808799743652,\n",
       "  'learning_rate': 0.0002875226039783002,\n",
       "  'loss': 6.1454,\n",
       "  'step': 265},\n",
       " {'epoch': 0.45454545454545453,\n",
       "  'eval_bpc': 2.68768723045308,\n",
       "  'eval_loss': 6.124334812164307,\n",
       "  'eval_perplexity': 520.6749877929688,\n",
       "  'eval_runtime': 10.133,\n",
       "  'eval_samples_per_second': 252.639,\n",
       "  'eval_steps_per_second': 3.947,\n",
       "  'step': 265},\n",
       " {'epoch': 0.4631217838765009,\n",
       "  'grad_norm': 2.9963040351867676,\n",
       "  'learning_rate': 0.000283001808318264,\n",
       "  'loss': 6.1596,\n",
       "  'step': 270},\n",
       " {'epoch': 0.4631217838765009,\n",
       "  'eval_bpc': 2.660614246735573,\n",
       "  'eval_loss': 6.1280341148376465,\n",
       "  'eval_perplexity': 493.677001953125,\n",
       "  'eval_runtime': 10.1358,\n",
       "  'eval_samples_per_second': 252.571,\n",
       "  'eval_steps_per_second': 3.946,\n",
       "  'step': 270},\n",
       " {'epoch': 0.4716981132075472,\n",
       "  'grad_norm': 7.06819486618042,\n",
       "  'learning_rate': 0.00027848101265822784,\n",
       "  'loss': 6.1491,\n",
       "  'step': 275},\n",
       " {'epoch': 0.4716981132075472,\n",
       "  'eval_bpc': 2.6940486754100963,\n",
       "  'eval_loss': 6.139100074768066,\n",
       "  'eval_perplexity': 456.0035095214844,\n",
       "  'eval_runtime': 10.1922,\n",
       "  'eval_samples_per_second': 251.173,\n",
       "  'eval_steps_per_second': 3.925,\n",
       "  'step': 275},\n",
       " {'epoch': 0.48027444253859347,\n",
       "  'grad_norm': 4.693238258361816,\n",
       "  'learning_rate': 0.00027396021699819167,\n",
       "  'loss': 6.1401,\n",
       "  'step': 280},\n",
       " {'epoch': 0.48027444253859347,\n",
       "  'eval_bpc': 2.7017844503930375,\n",
       "  'eval_loss': 6.126070022583008,\n",
       "  'eval_perplexity': 465.1763000488281,\n",
       "  'eval_runtime': 10.1425,\n",
       "  'eval_samples_per_second': 252.404,\n",
       "  'eval_steps_per_second': 3.944,\n",
       "  'step': 280},\n",
       " {'epoch': 0.4888507718696398,\n",
       "  'grad_norm': 3.3577020168304443,\n",
       "  'learning_rate': 0.0002694394213381555,\n",
       "  'loss': 6.1546,\n",
       "  'step': 285},\n",
       " {'epoch': 0.4888507718696398,\n",
       "  'eval_bpc': 2.7010880773283223,\n",
       "  'eval_loss': 6.124392509460449,\n",
       "  'eval_perplexity': 454.5027770996094,\n",
       "  'eval_runtime': 10.5971,\n",
       "  'eval_samples_per_second': 241.576,\n",
       "  'eval_steps_per_second': 3.775,\n",
       "  'step': 285},\n",
       " {'epoch': 0.4974271012006861,\n",
       "  'grad_norm': 4.026505947113037,\n",
       "  'learning_rate': 0.00026491862567811934,\n",
       "  'loss': 6.1261,\n",
       "  'step': 290},\n",
       " {'epoch': 0.4974271012006861,\n",
       "  'eval_bpc': 2.6648680901557147,\n",
       "  'eval_loss': 6.13232421875,\n",
       "  'eval_perplexity': 489.3540344238281,\n",
       "  'eval_runtime': 10.277,\n",
       "  'eval_samples_per_second': 249.101,\n",
       "  'eval_steps_per_second': 3.892,\n",
       "  'step': 290},\n",
       " {'epoch': 0.5060034305317325,\n",
       "  'grad_norm': 6.424472332000732,\n",
       "  'learning_rate': 0.00026039783001808323,\n",
       "  'loss': 6.1332,\n",
       "  'step': 295},\n",
       " {'epoch': 0.5060034305317325,\n",
       "  'eval_bpc': 2.671946879757796,\n",
       "  'eval_loss': 6.122216701507568,\n",
       "  'eval_perplexity': 463.40362548828125,\n",
       "  'eval_runtime': 10.1399,\n",
       "  'eval_samples_per_second': 252.468,\n",
       "  'eval_steps_per_second': 3.945,\n",
       "  'step': 295},\n",
       " {'epoch': 0.5145797598627787,\n",
       "  'grad_norm': 6.911288261413574,\n",
       "  'learning_rate': 0.00025587703435804706,\n",
       "  'loss': 6.1418,\n",
       "  'step': 300},\n",
       " {'epoch': 0.5145797598627787,\n",
       "  'eval_bpc': 2.694923073710073,\n",
       "  'eval_loss': 6.1279449462890625,\n",
       "  'eval_perplexity': 472.49725341796875,\n",
       "  'eval_runtime': 10.1625,\n",
       "  'eval_samples_per_second': 251.907,\n",
       "  'eval_steps_per_second': 3.936,\n",
       "  'step': 300},\n",
       " {'epoch': 0.5231560891938251,\n",
       "  'grad_norm': 3.539271831512451,\n",
       "  'learning_rate': 0.00025135623869801084,\n",
       "  'loss': 6.1386,\n",
       "  'step': 305},\n",
       " {'epoch': 0.5231560891938251,\n",
       "  'eval_bpc': 2.646833557166852,\n",
       "  'eval_loss': 6.114348888397217,\n",
       "  'eval_perplexity': 472.68450927734375,\n",
       "  'eval_runtime': 10.0743,\n",
       "  'eval_samples_per_second': 254.113,\n",
       "  'eval_steps_per_second': 3.971,\n",
       "  'step': 305},\n",
       " {'epoch': 0.5317324185248714,\n",
       "  'grad_norm': 5.422348499298096,\n",
       "  'learning_rate': 0.0002468354430379747,\n",
       "  'loss': 6.1203,\n",
       "  'step': 310},\n",
       " {'epoch': 0.5317324185248714,\n",
       "  'eval_bpc': 2.684975610541015,\n",
       "  'eval_loss': 6.133374214172363,\n",
       "  'eval_perplexity': 476.14019775390625,\n",
       "  'eval_runtime': 10.1429,\n",
       "  'eval_samples_per_second': 252.395,\n",
       "  'eval_steps_per_second': 3.944,\n",
       "  'step': 310},\n",
       " {'epoch': 0.5403087478559176,\n",
       "  'grad_norm': 4.0297441482543945,\n",
       "  'learning_rate': 0.0002423146473779385,\n",
       "  'loss': 6.1312,\n",
       "  'step': 315},\n",
       " {'epoch': 0.5403087478559176,\n",
       "  'eval_bpc': 2.6419787690898087,\n",
       "  'eval_loss': 6.106842041015625,\n",
       "  'eval_perplexity': 445.7306213378906,\n",
       "  'eval_runtime': 10.2051,\n",
       "  'eval_samples_per_second': 250.855,\n",
       "  'eval_steps_per_second': 3.92,\n",
       "  'step': 315},\n",
       " {'epoch': 0.548885077186964,\n",
       "  'grad_norm': 2.742964744567871,\n",
       "  'learning_rate': 0.00023779385171790235,\n",
       "  'loss': 6.1143,\n",
       "  'step': 320},\n",
       " {'epoch': 0.548885077186964,\n",
       "  'eval_bpc': 2.6466254164024865,\n",
       "  'eval_loss': 6.108910083770752,\n",
       "  'eval_perplexity': 450.32763671875,\n",
       "  'eval_runtime': 10.6246,\n",
       "  'eval_samples_per_second': 240.951,\n",
       "  'eval_steps_per_second': 3.765,\n",
       "  'step': 320},\n",
       " {'epoch': 0.5574614065180102,\n",
       "  'grad_norm': 5.650224685668945,\n",
       "  'learning_rate': 0.0002332730560578662,\n",
       "  'loss': 6.1166,\n",
       "  'step': 325},\n",
       " {'epoch': 0.5574614065180102,\n",
       "  'eval_bpc': 2.6709054993262273,\n",
       "  'eval_loss': 6.1188836097717285,\n",
       "  'eval_perplexity': 446.5537109375,\n",
       "  'eval_runtime': 10.3865,\n",
       "  'eval_samples_per_second': 246.474,\n",
       "  'eval_steps_per_second': 3.851,\n",
       "  'step': 325},\n",
       " {'epoch': 0.5660377358490566,\n",
       "  'grad_norm': 4.122164249420166,\n",
       "  'learning_rate': 0.00022875226039783004,\n",
       "  'loss': 6.1208,\n",
       "  'step': 330},\n",
       " {'epoch': 0.5660377358490566,\n",
       "  'eval_bpc': 2.6422065279418345,\n",
       "  'eval_loss': 6.108077526092529,\n",
       "  'eval_perplexity': 455.0201721191406,\n",
       "  'eval_runtime': 10.3202,\n",
       "  'eval_samples_per_second': 248.056,\n",
       "  'eval_steps_per_second': 3.876,\n",
       "  'step': 330},\n",
       " {'epoch': 0.5746140651801029,\n",
       "  'grad_norm': 2.93700909614563,\n",
       "  'learning_rate': 0.00022423146473779385,\n",
       "  'loss': 6.1289,\n",
       "  'step': 335},\n",
       " {'epoch': 0.5746140651801029,\n",
       "  'eval_bpc': 2.6665257861590916,\n",
       "  'eval_loss': 6.114742279052734,\n",
       "  'eval_perplexity': 498.6112976074219,\n",
       "  'eval_runtime': 10.6842,\n",
       "  'eval_samples_per_second': 239.606,\n",
       "  'eval_steps_per_second': 3.744,\n",
       "  'step': 335},\n",
       " {'epoch': 0.5831903945111492,\n",
       "  'grad_norm': 4.859701633453369,\n",
       "  'learning_rate': 0.00021971066907775768,\n",
       "  'loss': 6.1309,\n",
       "  'step': 340},\n",
       " {'epoch': 0.5831903945111492,\n",
       "  'eval_bpc': 2.693907705340461,\n",
       "  'eval_loss': 6.110814094543457,\n",
       "  'eval_perplexity': 426.2532653808594,\n",
       "  'eval_runtime': 10.2909,\n",
       "  'eval_samples_per_second': 248.763,\n",
       "  'eval_steps_per_second': 3.887,\n",
       "  'step': 340},\n",
       " {'epoch': 0.5917667238421955,\n",
       "  'grad_norm': 6.275849342346191,\n",
       "  'learning_rate': 0.00021518987341772155,\n",
       "  'loss': 6.1375,\n",
       "  'step': 345},\n",
       " {'epoch': 0.5917667238421955,\n",
       "  'eval_bpc': 2.68202221221842,\n",
       "  'eval_loss': 6.098280429840088,\n",
       "  'eval_perplexity': 461.2576904296875,\n",
       "  'eval_runtime': 10.294,\n",
       "  'eval_samples_per_second': 248.69,\n",
       "  'eval_steps_per_second': 3.886,\n",
       "  'step': 345},\n",
       " {'epoch': 0.6003430531732419,\n",
       "  'grad_norm': 3.5526387691497803,\n",
       "  'learning_rate': 0.00021066907775768535,\n",
       "  'loss': 6.1174,\n",
       "  'step': 350},\n",
       " {'epoch': 0.6003430531732419,\n",
       "  'eval_bpc': 2.7070705678287643,\n",
       "  'eval_loss': 6.110335350036621,\n",
       "  'eval_perplexity': 489.15338134765625,\n",
       "  'eval_runtime': 10.732,\n",
       "  'eval_samples_per_second': 238.54,\n",
       "  'eval_steps_per_second': 3.727,\n",
       "  'step': 350},\n",
       " {'epoch': 0.6089193825042881,\n",
       "  'grad_norm': 2.642051935195923,\n",
       "  'learning_rate': 0.0002061482820976492,\n",
       "  'loss': 6.1253,\n",
       "  'step': 355},\n",
       " {'epoch': 0.6089193825042881,\n",
       "  'eval_bpc': 2.6786665065215045,\n",
       "  'eval_loss': 6.107666492462158,\n",
       "  'eval_perplexity': 521.4553833007812,\n",
       "  'eval_runtime': 10.2478,\n",
       "  'eval_samples_per_second': 249.809,\n",
       "  'eval_steps_per_second': 3.903,\n",
       "  'step': 355},\n",
       " {'epoch': 0.6174957118353345,\n",
       "  'grad_norm': 3.033808469772339,\n",
       "  'learning_rate': 0.00020162748643761302,\n",
       "  'loss': 6.1035,\n",
       "  'step': 360},\n",
       " {'epoch': 0.6174957118353345,\n",
       "  'eval_bpc': 2.684357926430445,\n",
       "  'eval_loss': 6.1111931800842285,\n",
       "  'eval_perplexity': 452.6026306152344,\n",
       "  'eval_runtime': 10.1482,\n",
       "  'eval_samples_per_second': 252.261,\n",
       "  'eval_steps_per_second': 3.942,\n",
       "  'step': 360},\n",
       " {'epoch': 0.6260720411663808,\n",
       "  'grad_norm': 4.153578758239746,\n",
       "  'learning_rate': 0.00019710669077757686,\n",
       "  'loss': 6.1177,\n",
       "  'step': 365},\n",
       " {'epoch': 0.6260720411663808,\n",
       "  'eval_bpc': 2.6799101327152597,\n",
       "  'eval_loss': 6.117491722106934,\n",
       "  'eval_perplexity': 458.2449035644531,\n",
       "  'eval_runtime': 10.2072,\n",
       "  'eval_samples_per_second': 250.803,\n",
       "  'eval_steps_per_second': 3.919,\n",
       "  'step': 365},\n",
       " {'epoch': 0.6346483704974271,\n",
       "  'grad_norm': 4.078838348388672,\n",
       "  'learning_rate': 0.0001925858951175407,\n",
       "  'loss': 6.095,\n",
       "  'step': 370},\n",
       " {'epoch': 0.6346483704974271,\n",
       "  'eval_bpc': 2.604714159414037,\n",
       "  'eval_loss': 6.095734596252441,\n",
       "  'eval_perplexity': 473.0163879394531,\n",
       "  'eval_runtime': 10.1826,\n",
       "  'eval_samples_per_second': 251.409,\n",
       "  'eval_steps_per_second': 3.928,\n",
       "  'step': 370},\n",
       " {'epoch': 0.6432246998284734,\n",
       "  'grad_norm': 3.379042625427246,\n",
       "  'learning_rate': 0.00018806509945750452,\n",
       "  'loss': 6.1083,\n",
       "  'step': 375},\n",
       " {'epoch': 0.6432246998284734,\n",
       "  'eval_bpc': 2.6730666053916234,\n",
       "  'eval_loss': 6.0995192527771,\n",
       "  'eval_perplexity': 441.4547424316406,\n",
       "  'eval_runtime': 10.1753,\n",
       "  'eval_samples_per_second': 251.589,\n",
       "  'eval_steps_per_second': 3.931,\n",
       "  'step': 375},\n",
       " {'epoch': 0.6518010291595198,\n",
       "  'grad_norm': 4.600583553314209,\n",
       "  'learning_rate': 0.00018354430379746836,\n",
       "  'loss': 6.1161,\n",
       "  'step': 380},\n",
       " {'epoch': 0.6518010291595198,\n",
       "  'eval_bpc': 2.65792530243399,\n",
       "  'eval_loss': 6.088591575622559,\n",
       "  'eval_perplexity': 451.39288330078125,\n",
       "  'eval_runtime': 10.3083,\n",
       "  'eval_samples_per_second': 248.343,\n",
       "  'eval_steps_per_second': 3.88,\n",
       "  'step': 380},\n",
       " {'epoch': 0.660377358490566,\n",
       "  'grad_norm': 2.9006805419921875,\n",
       "  'learning_rate': 0.00017902350813743217,\n",
       "  'loss': 6.1033,\n",
       "  'step': 385},\n",
       " {'epoch': 0.660377358490566,\n",
       "  'eval_bpc': 2.715006166224665,\n",
       "  'eval_loss': 6.090394973754883,\n",
       "  'eval_perplexity': 427.58746337890625,\n",
       "  'eval_runtime': 10.4707,\n",
       "  'eval_samples_per_second': 244.492,\n",
       "  'eval_steps_per_second': 3.82,\n",
       "  'step': 385},\n",
       " {'epoch': 0.6689536878216124,\n",
       "  'grad_norm': 2.9080252647399902,\n",
       "  'learning_rate': 0.00017450271247739603,\n",
       "  'loss': 6.1063,\n",
       "  'step': 390},\n",
       " {'epoch': 0.6689536878216124,\n",
       "  'eval_bpc': 2.6579316122379475,\n",
       "  'eval_loss': 6.093739032745361,\n",
       "  'eval_perplexity': 453.8747253417969,\n",
       "  'eval_runtime': 10.2556,\n",
       "  'eval_samples_per_second': 249.619,\n",
       "  'eval_steps_per_second': 3.9,\n",
       "  'step': 390},\n",
       " {'epoch': 0.6775300171526587,\n",
       "  'grad_norm': 2.8848676681518555,\n",
       "  'learning_rate': 0.00016998191681735986,\n",
       "  'loss': 6.112,\n",
       "  'step': 395},\n",
       " {'epoch': 0.6775300171526587,\n",
       "  'eval_bpc': 2.7273014966898703,\n",
       "  'eval_loss': 6.086893081665039,\n",
       "  'eval_perplexity': 463.5194396972656,\n",
       "  'eval_runtime': 10.3895,\n",
       "  'eval_samples_per_second': 246.402,\n",
       "  'eval_steps_per_second': 3.85,\n",
       "  'step': 395},\n",
       " {'epoch': 0.6861063464837049,\n",
       "  'grad_norm': 5.128857135772705,\n",
       "  'learning_rate': 0.0001654611211573237,\n",
       "  'loss': 6.0992,\n",
       "  'step': 400},\n",
       " {'epoch': 0.6861063464837049,\n",
       "  'eval_bpc': 2.723815217290613,\n",
       "  'eval_loss': 6.094644546508789,\n",
       "  'eval_perplexity': 467.6772766113281,\n",
       "  'eval_runtime': 10.195,\n",
       "  'eval_samples_per_second': 251.104,\n",
       "  'eval_steps_per_second': 3.924,\n",
       "  'step': 400},\n",
       " {'epoch': 0.6946826758147513,\n",
       "  'grad_norm': 3.4250993728637695,\n",
       "  'learning_rate': 0.0001609403254972875,\n",
       "  'loss': 6.1078,\n",
       "  'step': 405},\n",
       " {'epoch': 0.6946826758147513,\n",
       "  'eval_bpc': 2.6982477081769187,\n",
       "  'eval_loss': 6.10384464263916,\n",
       "  'eval_perplexity': 484.4574890136719,\n",
       "  'eval_runtime': 10.1864,\n",
       "  'eval_samples_per_second': 251.315,\n",
       "  'eval_steps_per_second': 3.927,\n",
       "  'step': 405},\n",
       " {'epoch': 0.7032590051457976,\n",
       "  'grad_norm': 8.742398262023926,\n",
       "  'learning_rate': 0.00015641952983725136,\n",
       "  'loss': 6.1089,\n",
       "  'step': 410},\n",
       " {'epoch': 0.7032590051457976,\n",
       "  'eval_bpc': 2.628669307446646,\n",
       "  'eval_loss': 6.099854469299316,\n",
       "  'eval_perplexity': 400.0978698730469,\n",
       "  'eval_runtime': 10.4579,\n",
       "  'eval_samples_per_second': 244.79,\n",
       "  'eval_steps_per_second': 3.825,\n",
       "  'step': 410},\n",
       " {'epoch': 0.7118353344768439,\n",
       "  'grad_norm': 3.469590902328491,\n",
       "  'learning_rate': 0.0001518987341772152,\n",
       "  'loss': 6.1073,\n",
       "  'step': 415},\n",
       " {'epoch': 0.7118353344768439,\n",
       "  'eval_bpc': 2.6941014484211396,\n",
       "  'eval_loss': 6.095267295837402,\n",
       "  'eval_perplexity': 459.2414855957031,\n",
       "  'eval_runtime': 10.5758,\n",
       "  'eval_samples_per_second': 242.063,\n",
       "  'eval_steps_per_second': 3.782,\n",
       "  'step': 415},\n",
       " {'epoch': 0.7204116638078902,\n",
       "  'grad_norm': 3.4269490242004395,\n",
       "  'learning_rate': 0.00014737793851717903,\n",
       "  'loss': 6.1022,\n",
       "  'step': 420},\n",
       " {'epoch': 0.7204116638078902,\n",
       "  'eval_bpc': 2.7109256055296815,\n",
       "  'eval_loss': 6.084748268127441,\n",
       "  'eval_perplexity': 483.7388610839844,\n",
       "  'eval_runtime': 10.3699,\n",
       "  'eval_samples_per_second': 246.869,\n",
       "  'eval_steps_per_second': 3.857,\n",
       "  'step': 420},\n",
       " {'epoch': 0.7289879931389366,\n",
       "  'grad_norm': 3.0328986644744873,\n",
       "  'learning_rate': 0.00014285714285714284,\n",
       "  'loss': 6.0901,\n",
       "  'step': 425},\n",
       " {'epoch': 0.7289879931389366,\n",
       "  'eval_bpc': 2.6674567572026793,\n",
       "  'eval_loss': 6.099619388580322,\n",
       "  'eval_perplexity': 472.38323974609375,\n",
       "  'eval_runtime': 10.2005,\n",
       "  'eval_samples_per_second': 250.968,\n",
       "  'eval_steps_per_second': 3.921,\n",
       "  'step': 425},\n",
       " {'epoch': 0.7375643224699828,\n",
       "  'grad_norm': 3.209685802459717,\n",
       "  'learning_rate': 0.0001383363471971067,\n",
       "  'loss': 6.1077,\n",
       "  'step': 430},\n",
       " {'epoch': 0.7375643224699828,\n",
       "  'eval_bpc': 2.6710594508904775,\n",
       "  'eval_loss': 6.082414627075195,\n",
       "  'eval_perplexity': 468.8406066894531,\n",
       "  'eval_runtime': 10.2081,\n",
       "  'eval_samples_per_second': 250.781,\n",
       "  'eval_steps_per_second': 3.918,\n",
       "  'step': 430},\n",
       " {'epoch': 0.7461406518010292,\n",
       "  'grad_norm': 6.342111110687256,\n",
       "  'learning_rate': 0.00013381555153707054,\n",
       "  'loss': 6.0902,\n",
       "  'step': 435},\n",
       " {'epoch': 0.7461406518010292,\n",
       "  'eval_bpc': 2.6232705865342254,\n",
       "  'eval_loss': 6.0861663818359375,\n",
       "  'eval_perplexity': 437.5189514160156,\n",
       "  'eval_runtime': 10.3404,\n",
       "  'eval_samples_per_second': 247.572,\n",
       "  'eval_steps_per_second': 3.868,\n",
       "  'step': 435},\n",
       " {'epoch': 0.7547169811320755,\n",
       "  'grad_norm': 2.6704986095428467,\n",
       "  'learning_rate': 0.00012929475587703434,\n",
       "  'loss': 6.0904,\n",
       "  'step': 440},\n",
       " {'epoch': 0.7547169811320755,\n",
       "  'eval_bpc': 2.6522937303807717,\n",
       "  'eval_loss': 6.091462135314941,\n",
       "  'eval_perplexity': 427.2693176269531,\n",
       "  'eval_runtime': 10.3185,\n",
       "  'eval_samples_per_second': 248.098,\n",
       "  'eval_steps_per_second': 3.877,\n",
       "  'step': 440},\n",
       " {'epoch': 0.7632933104631218,\n",
       "  'grad_norm': 4.167417049407959,\n",
       "  'learning_rate': 0.00012477396021699818,\n",
       "  'loss': 6.0973,\n",
       "  'step': 445},\n",
       " {'epoch': 0.7632933104631218,\n",
       "  'eval_bpc': 2.6686761397131953,\n",
       "  'eval_loss': 6.082380771636963,\n",
       "  'eval_perplexity': 477.1217956542969,\n",
       "  'eval_runtime': 10.4209,\n",
       "  'eval_samples_per_second': 245.659,\n",
       "  'eval_steps_per_second': 3.838,\n",
       "  'step': 445},\n",
       " {'epoch': 0.7718696397941681,\n",
       "  'grad_norm': 3.084670066833496,\n",
       "  'learning_rate': 0.00012025316455696203,\n",
       "  'loss': 6.1075,\n",
       "  'step': 450},\n",
       " {'epoch': 0.7718696397941681,\n",
       "  'eval_bpc': 2.660148810031649,\n",
       "  'eval_loss': 6.082053184509277,\n",
       "  'eval_perplexity': 460.3684387207031,\n",
       "  'eval_runtime': 10.2476,\n",
       "  'eval_samples_per_second': 249.815,\n",
       "  'eval_steps_per_second': 3.903,\n",
       "  'step': 450},\n",
       " {'epoch': 0.7804459691252144,\n",
       "  'grad_norm': 2.9500646591186523,\n",
       "  'learning_rate': 0.00011573236889692586,\n",
       "  'loss': 6.094,\n",
       "  'step': 455},\n",
       " {'epoch': 0.7804459691252144,\n",
       "  'eval_bpc': 2.656362842400131,\n",
       "  'eval_loss': 6.083094120025635,\n",
       "  'eval_perplexity': 462.04315185546875,\n",
       "  'eval_runtime': 10.2608,\n",
       "  'eval_samples_per_second': 249.494,\n",
       "  'eval_steps_per_second': 3.898,\n",
       "  'step': 455},\n",
       " {'epoch': 0.7890222984562607,\n",
       "  'grad_norm': 5.239326477050781,\n",
       "  'learning_rate': 0.0001112115732368897,\n",
       "  'loss': 6.088,\n",
       "  'step': 460},\n",
       " {'epoch': 0.7890222984562607,\n",
       "  'eval_bpc': 2.6704504183057503,\n",
       "  'eval_loss': 6.091134548187256,\n",
       "  'eval_perplexity': 468.9298095703125,\n",
       "  'eval_runtime': 10.1583,\n",
       "  'eval_samples_per_second': 252.01,\n",
       "  'eval_steps_per_second': 3.938,\n",
       "  'step': 460},\n",
       " {'epoch': 0.7975986277873071,\n",
       "  'grad_norm': 4.306952953338623,\n",
       "  'learning_rate': 0.00010669077757685353,\n",
       "  'loss': 6.0901,\n",
       "  'step': 465},\n",
       " {'epoch': 0.7975986277873071,\n",
       "  'eval_bpc': 2.7465415563929967,\n",
       "  'eval_loss': 6.079509735107422,\n",
       "  'eval_perplexity': 459.5571594238281,\n",
       "  'eval_runtime': 10.1856,\n",
       "  'eval_samples_per_second': 251.336,\n",
       "  'eval_steps_per_second': 3.927,\n",
       "  'step': 465},\n",
       " {'epoch': 0.8061749571183533,\n",
       "  'grad_norm': 2.86551570892334,\n",
       "  'learning_rate': 0.00010216998191681736,\n",
       "  'loss': 6.0852,\n",
       "  'step': 470},\n",
       " {'epoch': 0.8061749571183533,\n",
       "  'eval_bpc': 2.7066560462707674,\n",
       "  'eval_loss': 6.0708513259887695,\n",
       "  'eval_perplexity': 453.52337646484375,\n",
       "  'eval_runtime': 10.184,\n",
       "  'eval_samples_per_second': 251.376,\n",
       "  'eval_steps_per_second': 3.928,\n",
       "  'step': 470},\n",
       " {'epoch': 0.8147512864493996,\n",
       "  'grad_norm': 3.0775537490844727,\n",
       "  'learning_rate': 9.76491862567812e-05,\n",
       "  'loss': 6.0831,\n",
       "  'step': 475},\n",
       " {'epoch': 0.8147512864493996,\n",
       "  'eval_bpc': 2.670324530823113,\n",
       "  'eval_loss': 6.075951099395752,\n",
       "  'eval_perplexity': 454.9388122558594,\n",
       "  'eval_runtime': 10.2312,\n",
       "  'eval_samples_per_second': 250.216,\n",
       "  'eval_steps_per_second': 3.91,\n",
       "  'step': 475},\n",
       " {'epoch': 0.823327615780446,\n",
       "  'grad_norm': 1.9001052379608154,\n",
       "  'learning_rate': 9.312839059674503e-05,\n",
       "  'loss': 6.0886,\n",
       "  'step': 480},\n",
       " {'epoch': 0.823327615780446,\n",
       "  'eval_bpc': 2.6260866840525323,\n",
       "  'eval_loss': 6.072151184082031,\n",
       "  'eval_perplexity': 462.3655700683594,\n",
       "  'eval_runtime': 10.2097,\n",
       "  'eval_samples_per_second': 250.742,\n",
       "  'eval_steps_per_second': 3.918,\n",
       "  'step': 480},\n",
       " {'epoch': 0.8319039451114922,\n",
       "  'grad_norm': 2.5909996032714844,\n",
       "  'learning_rate': 8.860759493670887e-05,\n",
       "  'loss': 6.0977,\n",
       "  'step': 485},\n",
       " {'epoch': 0.8319039451114922,\n",
       "  'eval_bpc': 2.6698054441632073,\n",
       "  'eval_loss': 6.083491802215576,\n",
       "  'eval_perplexity': 453.6427917480469,\n",
       "  'eval_runtime': 10.4059,\n",
       "  'eval_samples_per_second': 246.015,\n",
       "  'eval_steps_per_second': 3.844,\n",
       "  'step': 485},\n",
       " {'epoch': 0.8404802744425386,\n",
       "  'grad_norm': 3.375926971435547,\n",
       "  'learning_rate': 8.408679927667269e-05,\n",
       "  'loss': 6.1064,\n",
       "  'step': 490},\n",
       " {'epoch': 0.8404802744425386,\n",
       "  'eval_bpc': 2.5907923714621823,\n",
       "  'eval_loss': 6.082425594329834,\n",
       "  'eval_perplexity': 400.08203125,\n",
       "  'eval_runtime': 10.1733,\n",
       "  'eval_samples_per_second': 251.639,\n",
       "  'eval_steps_per_second': 3.932,\n",
       "  'step': 490},\n",
       " {'epoch': 0.8490566037735849,\n",
       "  'grad_norm': 4.065174579620361,\n",
       "  'learning_rate': 7.956600361663653e-05,\n",
       "  'loss': 6.0892,\n",
       "  'step': 495},\n",
       " {'epoch': 0.8490566037735849,\n",
       "  'eval_bpc': 2.594717482697975,\n",
       "  'eval_loss': 6.087140083312988,\n",
       "  'eval_perplexity': 432.23345947265625,\n",
       "  'eval_runtime': 10.1931,\n",
       "  'eval_samples_per_second': 251.15,\n",
       "  'eval_steps_per_second': 3.924,\n",
       "  'step': 495},\n",
       " {'epoch': 0.8576329331046312,\n",
       "  'grad_norm': 3.6810519695281982,\n",
       "  'learning_rate': 7.504520795660036e-05,\n",
       "  'loss': 6.0852,\n",
       "  'step': 500},\n",
       " {'epoch': 0.8576329331046312,\n",
       "  'eval_bpc': 2.692558796710009,\n",
       "  'eval_loss': 6.083384037017822,\n",
       "  'eval_perplexity': 421.7049255371094,\n",
       "  'eval_runtime': 10.1887,\n",
       "  'eval_samples_per_second': 251.258,\n",
       "  'eval_steps_per_second': 3.926,\n",
       "  'step': 500},\n",
       " {'epoch': 0.8662092624356775,\n",
       "  'grad_norm': 2.7444067001342773,\n",
       "  'learning_rate': 7.05244122965642e-05,\n",
       "  'loss': 6.0762,\n",
       "  'step': 505},\n",
       " {'epoch': 0.8662092624356775,\n",
       "  'eval_bpc': 2.673209491776784,\n",
       "  'eval_loss': 6.076441764831543,\n",
       "  'eval_perplexity': 456.8647155761719,\n",
       "  'eval_runtime': 10.2446,\n",
       "  'eval_samples_per_second': 249.888,\n",
       "  'eval_steps_per_second': 3.905,\n",
       "  'step': 505},\n",
       " {'epoch': 0.8747855917667239,\n",
       "  'grad_norm': 2.9436488151550293,\n",
       "  'learning_rate': 6.600361663652802e-05,\n",
       "  'loss': 6.0821,\n",
       "  'step': 510},\n",
       " {'epoch': 0.8747855917667239,\n",
       "  'eval_bpc': 2.6494045629942407,\n",
       "  'eval_loss': 6.075872898101807,\n",
       "  'eval_perplexity': 431.0315246582031,\n",
       "  'eval_runtime': 10.12,\n",
       "  'eval_samples_per_second': 252.963,\n",
       "  'eval_steps_per_second': 3.953,\n",
       "  'step': 510},\n",
       " {'epoch': 0.8833619210977701,\n",
       "  'grad_norm': 2.622983694076538,\n",
       "  'learning_rate': 6.148282097649186e-05,\n",
       "  'loss': 6.086,\n",
       "  'step': 515},\n",
       " {'epoch': 0.8833619210977701,\n",
       "  'eval_bpc': 2.6474990187965712,\n",
       "  'eval_loss': 6.070929050445557,\n",
       "  'eval_perplexity': 432.7494812011719,\n",
       "  'eval_runtime': 10.1608,\n",
       "  'eval_samples_per_second': 251.949,\n",
       "  'eval_steps_per_second': 3.937,\n",
       "  'step': 515},\n",
       " {'epoch': 0.8919382504288165,\n",
       "  'grad_norm': 2.3181698322296143,\n",
       "  'learning_rate': 5.696202531645569e-05,\n",
       "  'loss': 6.1006,\n",
       "  'step': 520},\n",
       " {'epoch': 0.8919382504288165,\n",
       "  'eval_bpc': 2.6444605260169807,\n",
       "  'eval_loss': 6.075986385345459,\n",
       "  'eval_perplexity': 474.11480712890625,\n",
       "  'eval_runtime': 10.1202,\n",
       "  'eval_samples_per_second': 252.96,\n",
       "  'eval_steps_per_second': 3.952,\n",
       "  'step': 520},\n",
       " {'epoch': 0.9005145797598628,\n",
       "  'grad_norm': 2.08394455909729,\n",
       "  'learning_rate': 5.244122965641953e-05,\n",
       "  'loss': 6.0697,\n",
       "  'step': 525},\n",
       " {'epoch': 0.9005145797598628,\n",
       "  'eval_bpc': 2.666513700560883,\n",
       "  'eval_loss': 6.06955623626709,\n",
       "  'eval_perplexity': 428.39892578125,\n",
       "  'eval_runtime': 10.1228,\n",
       "  'eval_samples_per_second': 252.895,\n",
       "  'eval_steps_per_second': 3.951,\n",
       "  'step': 525},\n",
       " {'epoch': 0.9090909090909091,\n",
       "  'grad_norm': 3.5192089080810547,\n",
       "  'learning_rate': 4.792043399638336e-05,\n",
       "  'loss': 6.0808,\n",
       "  'step': 530},\n",
       " {'epoch': 0.9090909090909091,\n",
       "  'eval_bpc': 2.6512289762482237,\n",
       "  'eval_loss': 6.054553031921387,\n",
       "  'eval_perplexity': 416.5308532714844,\n",
       "  'eval_runtime': 10.2201,\n",
       "  'eval_samples_per_second': 250.486,\n",
       "  'eval_steps_per_second': 3.914,\n",
       "  'step': 530},\n",
       " {'epoch': 0.9176672384219554,\n",
       "  'grad_norm': 4.582958698272705,\n",
       "  'learning_rate': 4.3399638336347196e-05,\n",
       "  'loss': 6.0919,\n",
       "  'step': 535},\n",
       " {'epoch': 0.9176672384219554,\n",
       "  'eval_bpc': 2.628475997448936,\n",
       "  'eval_loss': 6.065122127532959,\n",
       "  'eval_perplexity': 486.8252868652344,\n",
       "  'eval_runtime': 10.3499,\n",
       "  'eval_samples_per_second': 247.345,\n",
       "  'eval_steps_per_second': 3.865,\n",
       "  'step': 535},\n",
       " {'epoch': 0.9262435677530018,\n",
       "  'grad_norm': 2.8150293827056885,\n",
       "  'learning_rate': 3.887884267631103e-05,\n",
       "  'loss': 6.0914,\n",
       "  'step': 540},\n",
       " {'epoch': 0.9262435677530018,\n",
       "  'eval_bpc': 2.6745663682444487,\n",
       "  'eval_loss': 6.066812515258789,\n",
       "  'eval_perplexity': 468.976318359375,\n",
       "  'eval_runtime': 10.1905,\n",
       "  'eval_samples_per_second': 251.215,\n",
       "  'eval_steps_per_second': 3.925,\n",
       "  'step': 540},\n",
       " {'epoch': 0.934819897084048,\n",
       "  'grad_norm': 3.1398675441741943,\n",
       "  'learning_rate': 3.4358047016274865e-05,\n",
       "  'loss': 6.0909,\n",
       "  'step': 545},\n",
       " {'epoch': 0.934819897084048,\n",
       "  'eval_bpc': 2.668779072861391,\n",
       "  'eval_loss': 6.066514015197754,\n",
       "  'eval_perplexity': 451.93341064453125,\n",
       "  'eval_runtime': 10.1405,\n",
       "  'eval_samples_per_second': 252.454,\n",
       "  'eval_steps_per_second': 3.945,\n",
       "  'step': 545},\n",
       " {'epoch': 0.9433962264150944,\n",
       "  'grad_norm': 2.8372159004211426,\n",
       "  'learning_rate': 2.98372513562387e-05,\n",
       "  'loss': 6.0738,\n",
       "  'step': 550},\n",
       " {'epoch': 0.9433962264150944,\n",
       "  'eval_bpc': 2.6615114319044317,\n",
       "  'eval_loss': 6.072506427764893,\n",
       "  'eval_perplexity': 460.6354675292969,\n",
       "  'eval_runtime': 10.1478,\n",
       "  'eval_samples_per_second': 252.271,\n",
       "  'eval_steps_per_second': 3.942,\n",
       "  'step': 550},\n",
       " {'epoch': 0.9519725557461407,\n",
       "  'grad_norm': 2.2822699546813965,\n",
       "  'learning_rate': 2.5316455696202533e-05,\n",
       "  'loss': 6.0558,\n",
       "  'step': 555},\n",
       " {'epoch': 0.9519725557461407,\n",
       "  'eval_bpc': 2.6641893767526437,\n",
       "  'eval_loss': 6.0658159255981445,\n",
       "  'eval_perplexity': 420.1706237792969,\n",
       "  'eval_runtime': 10.1568,\n",
       "  'eval_samples_per_second': 252.048,\n",
       "  'eval_steps_per_second': 3.938,\n",
       "  'step': 555},\n",
       " {'epoch': 0.9605488850771869,\n",
       "  'grad_norm': 3.5464138984680176,\n",
       "  'learning_rate': 2.0795660036166368e-05,\n",
       "  'loss': 6.0701,\n",
       "  'step': 560},\n",
       " {'epoch': 0.9605488850771869,\n",
       "  'eval_bpc': 2.6726002398279043,\n",
       "  'eval_loss': 6.062925815582275,\n",
       "  'eval_perplexity': 466.49798583984375,\n",
       "  'eval_runtime': 10.1423,\n",
       "  'eval_samples_per_second': 252.409,\n",
       "  'eval_steps_per_second': 3.944,\n",
       "  'step': 560},\n",
       " {'epoch': 0.9691252144082333,\n",
       "  'grad_norm': 3.3534133434295654,\n",
       "  'learning_rate': 1.6274864376130202e-05,\n",
       "  'loss': 6.0535,\n",
       "  'step': 565},\n",
       " {'epoch': 0.9691252144082333,\n",
       "  'eval_bpc': 2.6606756617377605,\n",
       "  'eval_loss': 6.063547611236572,\n",
       "  'eval_perplexity': 424.2338562011719,\n",
       "  'eval_runtime': 10.1574,\n",
       "  'eval_samples_per_second': 252.034,\n",
       "  'eval_steps_per_second': 3.938,\n",
       "  'step': 565},\n",
       " {'epoch': 0.9777015437392796,\n",
       "  'grad_norm': 1.933772325515747,\n",
       "  'learning_rate': 1.1754068716094033e-05,\n",
       "  'loss': 6.0818,\n",
       "  'step': 570},\n",
       " {'epoch': 0.9777015437392796,\n",
       "  'eval_bpc': 2.6434488640792417,\n",
       "  'eval_loss': 6.061529159545898,\n",
       "  'eval_perplexity': 455.8898010253906,\n",
       "  'eval_runtime': 10.479,\n",
       "  'eval_samples_per_second': 244.298,\n",
       "  'eval_steps_per_second': 3.817,\n",
       "  'step': 570},\n",
       " {'epoch': 0.9862778730703259,\n",
       "  'grad_norm': 1.8717360496520996,\n",
       "  'learning_rate': 7.233273056057866e-06,\n",
       "  'loss': 6.0839,\n",
       "  'step': 575},\n",
       " {'epoch': 0.9862778730703259,\n",
       "  'eval_bpc': 2.652499136217948,\n",
       "  'eval_loss': 6.079807281494141,\n",
       "  'eval_perplexity': 498.8081970214844,\n",
       "  'eval_runtime': 10.1335,\n",
       "  'eval_samples_per_second': 252.627,\n",
       "  'eval_steps_per_second': 3.947,\n",
       "  'step': 575},\n",
       " {'epoch': 0.9948542024013722,\n",
       "  'grad_norm': 2.29225492477417,\n",
       "  'learning_rate': 2.7124773960216997e-06,\n",
       "  'loss': 6.0718,\n",
       "  'step': 580},\n",
       " {'epoch': 0.9948542024013722,\n",
       "  'eval_bpc': 2.6721260877401387,\n",
       "  'eval_loss': 6.063088417053223,\n",
       "  'eval_perplexity': 441.6916198730469,\n",
       "  'eval_runtime': 10.1052,\n",
       "  'eval_samples_per_second': 253.335,\n",
       "  'eval_steps_per_second': 3.958,\n",
       "  'step': 580}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get('log_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_bpc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_history\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "[log['eval_bpc'] for log in data['log_history']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
