{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS_FOLDER = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(model_folder: str) -> str:\n",
    "    \"\"\"Loads from local checkpoint. Loads the checkpoint with the highest number.\n",
    "\n",
    "    Args:\n",
    "        model_folder (str): model folder with may contain multiple checkpoints.\n",
    "\n",
    "    Returns:\n",
    "        str: returns the checkpoint with the highest number\n",
    "    \"\"\"\n",
    "    checkpoints = [d for d in os.listdir(model_folder) if d.startswith(\"checkpoint-\")]\n",
    "\n",
    "    if not checkpoints:\n",
    "        print(f\"No checkpoints found in {model_folder}\")\n",
    "        exit()\n",
    "\n",
    "    # Find the checkpoint with the highest step number\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]), reverse=True)\n",
    "    checkpoint_dir = os.path.join(model_folder, checkpoints[0])\n",
    "\n",
    "    return checkpoint_dir\n",
    "\n",
    "\n",
    "def num_params(model) -> None:\n",
    "    \"\"\"\n",
    "    Prints the total number of parameters in the model in millions.\n",
    "\n",
    "    Args:\n",
    "        model: The model whose parameters are to be counted.\n",
    "    \"\"\"\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    num_params_million = num_params / 1e6\n",
    "    return f\"{num_params_million:.2f}M\"\n",
    "\n",
    "\n",
    "def process_model_folders(base_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Processes folders with the 'language_tokenizer_vs' pattern to load the model with the highest checkpoint and get the parameters.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): The base directory containing model folders.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with folder names as keys and their corresponding model parameter counts as values.\n",
    "    \"\"\"\n",
    "    num_params_dict = {}\n",
    "    # Iterate through folders starting with 'language_tokenizer_vs' and ending with a digit\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        if folder_name[-1].isdigit():\n",
    "            model_folder = os.path.join(base_dir, folder_name)\n",
    "\n",
    "            # Load the checkpoint with the highest number\n",
    "            checkpoint_dir = load_model_from_checkpoint(model_folder)\n",
    "            \n",
    "            # Load the model\n",
    "            model = AutoModel.from_pretrained(checkpoint_dir)\n",
    "\n",
    "            # Get the number of parameters\n",
    "            params = num_params(model)\n",
    "\n",
    "            # Store the result in the dictionary\n",
    "            num_params_dict[folder_name] = params\n",
    "            \n",
    "    return num_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_model_folders(ALL_MODELS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_es_BPE_vs10000': '7.95M',\n",
       " 'model_es_BPE_vs20000': '11.07M',\n",
       " 'model_es_BPE_vs30000': '14.19M',\n",
       " 'model_es_BPE_vs40000': '17.31M',\n",
       " 'model_es_Unigram_vs10000': '7.95M',\n",
       " 'model_es_Unigram_vs20000': '11.07M',\n",
       " 'model_es_Unigram_vs30000': '14.19M',\n",
       " 'model_es_Unigram_vs40000': '17.31M',\n",
       " 'model_es_Wordpiece_vs10000': '7.95M',\n",
       " 'model_es_Wordpiece_vs20000': '11.07M',\n",
       " 'model_es_Wordpiece_vs30000': '14.19M',\n",
       " 'model_es_Wordpiece_vs40000': '17.31M',\n",
       " 'model_tr_BPE_vs10000': '7.95M',\n",
       " 'model_tr_BPE_vs20000': '11.07M',\n",
       " 'model_tr_BPE_vs30000': '14.19M',\n",
       " 'model_tr_BPE_vs40000': '17.31M',\n",
       " 'model_tr_Unigram_vs10000': '7.95M',\n",
       " 'model_tr_Unigram_vs20000': '11.07M',\n",
       " 'model_tr_Unigram_vs30000': '14.19M',\n",
       " 'model_tr_Unigram_vs40000': '17.31M',\n",
       " 'model_tr_Wordpiece_vs10000': '7.95M',\n",
       " 'model_tr_Wordpiece_vs20000': '11.07M',\n",
       " 'model_tr_Wordpiece_vs30000': '14.19M',\n",
       " 'model_tr_Wordpiece_vs40000': '17.31M'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
